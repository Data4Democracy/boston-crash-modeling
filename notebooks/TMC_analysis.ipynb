{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import folium\n",
    "import pandas as pd\n",
    "os.chdir('../src/data')\n",
    "import util\n",
    "os.chdir('../../notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Right': 563, u'crash_count': 1, u'Longitude': u'-71.0631259', u'Filename': u'7436_2407_BUNKER-HILL-ST,-MYSTIC-ST,-SCHOOL-ST_NA_NA_CHARLESTOWN_11-HOURS_NA_09-18-2014.XLS', u'Hours': u'11', u'Date': u'2014-09-18', u'near_intersection_id': u'8032', u'Normalized': 6046, u'Address': u'Mystic St & Bunker Hill St, Boston, MA 02129, USA', u'Latitude': u'42.379195', u'near_id': 8032, u'Total': 4430, u'Conflict': 529, u'Left': 529}\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_DATA_FP = '../data/processed/'\n",
    "\n",
    "inters = {}\n",
    "with open(PROCESSED_DATA_FP + 'inters_data.json') as f:\n",
    "    data = json.load(f)\n",
    "    for key, value in data.iteritems():\n",
    "        inters[str(key)] = value[0]\n",
    "\n",
    "with open(PROCESSED_DATA_FP + 'tmc_summary.json') as f:\n",
    "    addresses = json.load(f)\n",
    "\n",
    "    print addresses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_crashes():\n",
    "\n",
    "    count = 0\n",
    "    print 'comparing.........'\n",
    "    inters = {}\n",
    "    with open(PROCESSED_DATA_FP + 'inters_data.json') as f:\n",
    "        print 'yay'\n",
    "        data = json.load(f)\n",
    "        for key, value in data.iteritems():\n",
    "            inters[str(key)] = value[0]\n",
    "\n",
    "    print inters.values()[0]\n",
    "\n",
    "    crashes_by_seg = {}\n",
    "    with open(PROCESSED_DATA_FP + 'crash_joined.json') as f:\n",
    "        data = json.load(f)\n",
    "        for row in data:\n",
    "            if str(row['near_id']) == '':\n",
    "                next\n",
    "            if str(row['near_id']) not in crashes_by_seg.keys():\n",
    "                crashes_by_seg[str(row['near_id'])] = {\n",
    "                    'total': 0, 'type': [], 'values': []}\n",
    "            crashes_by_seg[str(row['near_id'])]['total'] += 1\n",
    "            crashes_by_seg[str(row['near_id'])]['type'].append(\n",
    "                row['FIRST_EVENT_SUBTYPE'])\n",
    "            crashes_by_seg[str(row['near_id'])]['values'].append(row)\n",
    "            \n",
    "#    print len(crashes_by_seg.keys())      \n",
    "\n",
    "    count = 0\n",
    "    max = 0\n",
    "    max_intersection = None\n",
    "\n",
    "    high_crashes = []\n",
    "    single_crash = []\n",
    "    no_crashes = []\n",
    "    crash_tuples = []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    crash_count = []\n",
    "    crash_volume = []\n",
    "    crash_speed = []\n",
    "    crash_speed_bins = []\n",
    "    with open(PROCESSED_DATA_FP + 'tmc_summary.json') as f:\n",
    "        data = json.load(f)\n",
    "        for row in data:\n",
    "            if str(row['near_intersection_id']) in crashes_by_seg.keys() \\\n",
    "               and row['near_intersection_id'] != '':\n",
    "                crashes = crashes_by_seg[str(row['near_intersection_id'])]\n",
    "                row['Crashes'] = crashes['total']\n",
    "                row['Types'] = crashes['type']\n",
    "                row['Speed'] = inters[str(row['near_intersection_id'])]['SPEEDLIMIT']\n",
    "                results.append(row)\n",
    "\n",
    "                crash_tuples.append((\n",
    "                    crashes['total'], str(row['near_intersection_id']), row['Normalized']))\n",
    "                if row['Normalized']:\n",
    "                    crash_count.append(float(crashes['total']))\n",
    "#                    print row['Normalized']                                                                                                                            \n",
    "                    crash_volume.append(float(row['Normalized']))\n",
    "                    crash_speed.append(float(row['Speed']))\n",
    "                    if row['Speed'] < 20:\n",
    "                        crash_speed_bins.append(float(1))\n",
    "                    elif row['Speed'] < 30:\n",
    "                        crash_speed_bins.append(float(2))\n",
    "                    else:\n",
    "                        crash_speed_bins.append(float(3))\n",
    "                if crashes['total'] > max:\n",
    "                    max = crashes['total']\n",
    "                    max_intersection = row\n",
    "                    \n",
    "                if crashes['total'] > 1:\n",
    "                    if row['Normalized']:\n",
    "                        high_crashes.append(row['Normalized'])\n",
    "                else:\n",
    "                    if row['Normalized']:\n",
    "                        single_crash.append(row['Normalized'])\n",
    "            else:\n",
    "                if row['Normalized']:\n",
    "                    no_crashes.append(row['Normalized'])\n",
    "                count += 1\n",
    "\n",
    "#    print '8028' in crashes_by_seg.keys()                                                                                                                              \n",
    "    high_crashes.sort()\n",
    "    single_crash.sort()\n",
    "    no_crashes.sort()\n",
    "#    print high_crashes                                                                                                                                                 \n",
    "#    print sum(high_crashes)/len(high_crashes)                                                                                                                          \n",
    "\n",
    "#    print sum(single_crash)/len(single_crash)                                                                                                                          \n",
    "#    print no_crashes                                                                                                                                                   \n",
    "#    print sum(no_crashes)/len(no_crashes)                                                                                                                              \n",
    "#    print max                                                                                                                                                          \n",
    "#    print max_intersection\n",
    "\n",
    "    for i in range(2):\n",
    "        print results[i]\n",
    "\n",
    "    import numpy\n",
    "    print numpy.corrcoef([crash_count, crash_speed_bins])\n",
    "#    print crash_tuples                                                                                                                                                 \n",
    "\n",
    "    sorted_results = sorted(results, key=lambda k: k['Normalized'])\n",
    "    print sorted_results[0]\n",
    "    print sorted_results[len(results)-1]\n",
    "    print len(sorted_results)\n",
    "    # count = 0                                                                                                                                                         \n",
    "    print single_crash\n",
    "    print high_crashes\n",
    "    #     if tmc['properties']['near_id'] in crashes_by_seg.keys():                                                                                                     \n",
    "    #         print tmc['properties']                                                                                                                                   \n",
    "    #     count += 1                                                                                                                                                    \n",
    "    # print \"count::::::::::::::::::::\" + str(count)                                                                                                                    \n",
    "    # print len(crashes_by_seg)                                                                                                                                         \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_atrs(tmcs):\n",
    "    atrs = {}\n",
    "    count = 0\n",
    "    with open(PROCESSED_DATA_FP + 'snapped_atrs.json') as f:\n",
    "        data = json.load(f)\n",
    "        print data[0]\n",
    "        for row in data:\n",
    "            if row['near_id']:\n",
    "                atrs[row['near_id']] = row\n",
    "    for tmc in tmcs:\n",
    "        if tmc['properties']['near_id'] in atrs.keys():\n",
    "            print \"------------------------------------------\"\n",
    "            print tmc['properties']\n",
    "            print atrs[tmc['properties']['near_id']]\n",
    "            print \"..........................................\"\n",
    "            count += 1\n",
    "    print count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_tmcs(addresses):\n",
    "\n",
    "    # First create basemap                                                                                                                                              \n",
    "    points = folium.Map(\n",
    "        [42.3601, -71.0589],\n",
    "        tiles='Cartodb Positron',\n",
    "        zoom_start=12\n",
    "    )\n",
    "\n",
    "    # plot tmcs                                                                                                                                                         \n",
    "    for address in addresses:\n",
    "        if not pd.isnull(address['Latitude']):\n",
    "            folium.CircleMarker(\n",
    "                location=[float(address['Latitude']), float(address['Longitude'])],\n",
    "                fill_color='yellow', fill=True, fill_opacity=.7, color='yellow',\n",
    "                radius=6.0).add_to(points)\n",
    "\n",
    "    # Plot atrs                                                                                                                                                         \n",
    "    atrs = util.csv_to_projected_records(\n",
    "        PROCESSED_DATA_FP + 'geocoded_atrs.csv', x='lng', y='lat')\n",
    "    for atr in atrs:\n",
    "        properties = atr['properties']\n",
    "        if properties['lat']:\n",
    "            folium.CircleMarker(\n",
    "                location=[float(properties['lat']), float(properties['lng'])],\n",
    "                fill_color='green', fill=True, fill_opacity=.7, color='grey',\n",
    "                radius=6.0).add_to(points)\n",
    "\n",
    "    points.save('map.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_crashes()\n",
    "plot_tmcs(addresses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
