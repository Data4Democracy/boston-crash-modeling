{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model for crash prediction\n",
    "### Developed by: bpben\n",
    "#### Details steps of data processing, feature engineering and model tuning/testing for crash and road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers for tuning/testing models, available [here](https://github.com/bpben/model_helpers) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble as ske\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn import metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import model_selection as cv\n",
    "\n",
    "class Indata():\n",
    "    scoring = None\n",
    "    data = None\n",
    "    train_x, train_y, test_x, test_y = None, None, None, None\n",
    "    is_split = 0\n",
    "    \n",
    "    #init with pandas DF and target column name, specify scoring observations\n",
    "    def __init__(self, data, target, scoring=None):\n",
    "        #If scoring observations, store under scoring attribute\n",
    "        if scoring is not None:\n",
    "            self.data = data[~(scoring)]\n",
    "            self.scoring = data[scoring]\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.target = target\n",
    "    \n",
    "    # Split into train/test\n",
    "    # pct = percent training observations\n",
    "    # datesort = specify date column for sorting values\n",
    "    #   If this is not None, split will be non-random (i.e. split on sorted obs)\n",
    "    def tr_te_split(self, pct, datesort=None):\n",
    "        if datesort:\n",
    "            self.data.sort_values(datesort, inplace=True)\n",
    "            self.data.reset_index(drop=True, inplace=True)\n",
    "            inds = np.arange(0.0,len(self.data)) / len(self.data) < pct\n",
    "        else:\n",
    "            inds = np.random.rand(len(self.data)) < pct\n",
    "        self.train_x = self.data[inds]\n",
    "        print 'Train obs:', len(self.train_x)\n",
    "        self.train_y = self.data[self.target][inds]\n",
    "        self.test_x = self.data[~inds]\n",
    "        print 'Test obs:', len(self.test_x)\n",
    "        self.test_y = self.data[self.target][~inds]\n",
    "        self.is_split = 1\n",
    "        \n",
    "class Tuner():\n",
    "    \"\"\"\n",
    "    Initiates with indata class, will tune series of models according to parameters.  \n",
    "    Outputs RandomizedGridCV results and parameterized model in dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    data = None\n",
    "    train_x, train_y = None, None\n",
    "    \n",
    "    def __init__(self, indata, best_models=None, grid_results=None):\n",
    "        if indata.is_split == 0:\n",
    "            raise ValueError('Data is not split, cannot be tested')\n",
    "        else:\n",
    "            self.data = indata.data\n",
    "            self.train_x = indata.train_x\n",
    "            self.train_y = indata.train_y\n",
    "            if best_models is None:\n",
    "                self.best_models = {}\n",
    "            if grid_results is None:\n",
    "                self.grid_results = pd.DataFrame()\n",
    "        \n",
    "            \n",
    "    def make_grid(self, model, obs, cvparams, mparams):\n",
    "        #Makes CV grid\n",
    "        grid = RandomizedSearchCV(\n",
    "                    model(),scoring=cvparams['pmetric'], \n",
    "                    cv = cv.KFold(cvparams['folds']), \n",
    "                    refit=False, n_iter=cvparams['iter'],\n",
    "                    param_distributions=mparams, verbose=1)\n",
    "        return(grid)\n",
    "    \n",
    "    def run_grid(self, grid, train_x, train_y):\n",
    "        grid.fit(train_x, train_y)\n",
    "        results = pd.DataFrame(grid.cv_results_)[['mean_test_score','mean_train_score','params']]\n",
    "        best = {}\n",
    "        best['bp'] = grid.best_params_\n",
    "        best[grid.scoring] = grid.best_score_\n",
    "        return(best, results)\n",
    "            \n",
    "    def tune(self, name, m_name, features, cvparams, mparams):\n",
    "        if hasattr(ske, m_name):\n",
    "            model = getattr(ske, m_name)\n",
    "        elif hasattr(skl, m_name):\n",
    "            model = getattr(skl, m_name)\n",
    "        else:\n",
    "            raise ValueError('Model name is invalid.')\n",
    "        grid = self.make_grid(model, len(self.train_x), cvparams, mparams)\n",
    "        best, results = self.run_grid(grid, self.train_x[features], self.train_y)\n",
    "        results['name'] = name\n",
    "        results['m_name'] = m_name\n",
    "        self.grid_results = self.grid_results.append(results)\n",
    "        best['model'] = model(**best['bp'])\n",
    "        best['features'] = list(features)\n",
    "        self.best_models.update({name: best}) \n",
    "        \n",
    "class Tester():\n",
    "    \"\"\"\n",
    "    Initiates with indata class, receives parameterized sklearn models, prints and stores results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, rundict=None):\n",
    "        if data.is_split == 0 :\n",
    "            raise ValueError('Data is not split, cannot be tested')\n",
    "        else:\n",
    "            self.data = data\n",
    "            if rundict is None:\n",
    "                self.rundict = {}\n",
    "            \n",
    "    #Add tuner object, will populate rundict with names, models, feature\n",
    "    def init_tuned(self, tuned):\n",
    "        if tuned.best_models=={}:\n",
    "            raise ValueError('No tuned models found')\n",
    "        else:\n",
    "            self.rundict.update(tuned.best_models)\n",
    "    \n",
    "    #Produce predicted class and probabilities\n",
    "    def predsprobs(self, model, test_x):\n",
    "        preds = model.predict(test_x)\n",
    "        probs = model.predict_proba(test_x)[:,1]\n",
    "        return(preds, probs)\n",
    "    \n",
    "    #Produce metrics\n",
    "    def get_metrics(self, preds, probs, test_y):\n",
    "        f1_s = metrics.f1_score(test_y, preds)\n",
    "        brier = metrics.brier_score_loss(test_y, probs)\n",
    "        auc = metrics.roc_auc_score(test_y, preds)\n",
    "        c_matrix = metrics.confusion_matrix(test_y, preds)\n",
    "        return(f1_s, brier, auc, c_matrix)\n",
    "    \n",
    "    #Run production, output dictionary\n",
    "    def make_result(self, model, test_x, test_y):\n",
    "        preds, probs = self.predsprobs(model, test_x)\n",
    "        f1_s, brier, auc, c_matrix = self.get_metrics(preds, probs, test_y)\n",
    "        print \"f1_score: \", f1_s\n",
    "        print \"brier_score: \", brier\n",
    "        print \"AUC score: \", auc\n",
    "        print \"Confusion Matrix: \", c_matrix\n",
    "        result = {}\n",
    "        #result['preds'] = [int(i) for i in preds]\n",
    "        #result['probs'] = [float(i) for i in probs]\n",
    "        result['f1_s'] = f1_s\n",
    "        result['brier'] = brier\n",
    "        result['auc'] = auc\n",
    "        result['c_matrix'] = c_matrix\n",
    "        return(result)\n",
    "\n",
    "    # Run model - Specify model, with parameters, features\n",
    "    # Stores it to rundict, can later be output\n",
    "    # Will overwrite previous run if name is not different\n",
    "    def run_model(self, name, model, features, cal=True, cal_m='sigmoid'):\n",
    "        results = {}\n",
    "        results['features'] = list(features)\n",
    "        print \"Fitting {} model with {} features\".format(name, len(features))\n",
    "        if cal:\n",
    "            # Need disjoint calibration/training datasets\n",
    "            # Split 50/50\n",
    "            rnd_ind = np.random.rand(len(self.data.train_x)) < .5\n",
    "            train_x = self.data.train_x[features][rnd_ind]\n",
    "            train_y = self.data.train_y[rnd_ind]\n",
    "            cal_x = self.data.train_x[features][~rnd_ind]\n",
    "            cal_y = self.data.train_y[~rnd_ind]\n",
    "        else:\n",
    "            train_x = self.data.train_x[features]\n",
    "            train_y = self.data.train_y\n",
    "\n",
    "        m_fit = model.fit(train_x, train_y)\n",
    "        result = self.make_result(\n",
    "            m_fit,\n",
    "            self.data.test_x[features],\n",
    "            self.data.test_y)\n",
    "\n",
    "        results['raw'] = result\n",
    "        results['m_fit'] = m_fit\n",
    "        if cal:\n",
    "            print \"calibrated:\"\n",
    "            m_c = CalibratedClassifierCV(m_fit, method = cal_m, cv='prefit')\n",
    "            m_fit_c = m_c.fit(cal_x, cal_y)\n",
    "            result_c = self.make_result(m_fit_c, self.data.test_x[features], self.data.test_y)\n",
    "            results['calibrated'] = result_c              \n",
    "            print \"\\n\"\n",
    "        if name in self.rundict:\n",
    "            self.rundict[name].update(results)\n",
    "        else:\n",
    "            self.rundict.update({name:results})\n",
    "    \n",
    "    #Run from tuned set\n",
    "    def run_tuned(self, name, cal=True, cal_m='sigmoid'):\n",
    "        self.run_model(name, self.rundict[name]['model'], self.rundict[name]['features'], cal, cal_m)\n",
    "    \n",
    "    #Output rundict to csv\n",
    "    def to_csv(self):\n",
    "        if self.rundict == {}:\n",
    "            raise ValueError('No results found')\n",
    "        else:\n",
    "            now = pd.to_datetime('today').value\n",
    "            #Make dataframe, transpose so each row = model\n",
    "            pd.DataFrame(self.rundict).T.to_csv('results_{}.csv'.format(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "The approach here is to create 3 time-lag features:\n",
    "\n",
    "1. crashes in the past week\n",
    "2. crashes in the past month\n",
    "3. crashes in the past quarter (three months)\n",
    "4. average crashes per week up to target week\n",
    "\n",
    "All features except 4 are calculated to exclude one another.  That is, crashes in the past month does not include the past week's crashes.  Crashes in the past quarter do not include the past month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEG_CHARS = ['AADT', 'SPEEDLIMIT', 'Struct_Cnd', 'Surface_Tp', 'F_F_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('../../data/processed/vz_predict_dataset.csv.gz', compression='gzip', dtype={'segment_id':'str'})\n",
    "data.sort_values(['segment_id', 'year', 'week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get segments with non-zero crashes\n",
    "data_nonzero = data.set_index('segment_id').loc[data.groupby('segment_id').crash.sum()>0]\n",
    "data_nonzero.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_crash_data(data, col, target_week, target_year):\n",
    "    \"\"\" formats crash data for train/test \n",
    "    target_week: week to predict (make into binary target)\n",
    "    target_year: year for predicted week\n",
    "    note: data must be available for 4 months prior to target\n",
    "    gets previous week count, previous month count, previous quarter count, avg per week\n",
    "    \"\"\"\n",
    "    assert target_week>16\n",
    "    pre_week = target_week - 1\n",
    "    pre_month = range(pre_week-4, target_week)\n",
    "    pre_quarter = range(pre_month[0]-12, target_week)\n",
    "    \n",
    "    # week interval for each segment\n",
    "    # full range = pre_quarter : target\n",
    "    sliced = data.loc[(slice(None),slice(target_year,target_year), slice(1, target_week)),:]\n",
    "    week_data = sliced[col].unstack(2)\n",
    "    week_data.reset_index(level=1, inplace=True)\n",
    "    \n",
    "    # aggregate\n",
    "    week_data['pre_month'] = week_data[pre_month].sum(axis=1)\n",
    "    week_data['pre_quarter'] = week_data[pre_quarter].sum(axis=1)\n",
    "    week_data['pre_week'] = week_data[pre_week]\n",
    "\n",
    "    # avg as of target week\n",
    "    except_target = data.loc[(slice(None),\n",
    "                       slice(target_year,target_year),\n",
    "                       slice(target_week,None)),:].index\n",
    "    avg_week = data.drop(except_target)\n",
    "    avg_week = avg_week.reset_index().groupby('segment_id')[col].mean()\n",
    "    avg_week.name = 'avg_week'\n",
    "    # join to week data\n",
    "    week_data = week_data.join(avg_week)\n",
    "\n",
    "    # binarize target\n",
    "    week_data['target'] = (week_data[target_week]>0).astype(int)\n",
    "    week_data = week_data.reset_index()\n",
    "\n",
    "    return(week_data[['segment_id','target', 'pre_week',\n",
    "                      'pre_month', 'pre_quarter', 'avg_week']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crash_lags = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', 19, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_segs = data_nonzero.groupby('segment_id')[SEG_CHARS].max()  # grab the highest values from each column for a segment, not used in model?\n",
    "data_segs.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model = crash_lags.merge(data_segs, left_on='segment_id', right_on='segment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in adjacency info\n",
    "adj_info = pd.read_csv('../../data/processed/adjacency_info.csv', usecols=['segment_id', 'orig_id'],\n",
    "                       dtype={'segment_id':'str', 'orig_id':'str'})\n",
    "\n",
    "# link adjacent segments for segments with crashes\n",
    "adj_info = adj_info[adj_info.segment_id.isin(data_model.segment_id)]\n",
    "adj_mat = adj_info.merge(adj_info, on='orig_id')\n",
    "adj_mat = adj_mat[['segment_id_x', 'segment_id_y']]\n",
    "adj_mat.drop_duplicates(inplace=True)\n",
    "# including segments with only self-adjacent\n",
    "# for this, need to ensure they don't join to their own data\n",
    "adj_mat.loc[adj_mat.segment_id_x==adj_mat.segment_id_y, 'segment_id_y'] = np.NaN\n",
    "\n",
    "def get_adj_crash_lags(target_week, target_year):\n",
    "    \"\"\"calculate total number of crashes that occurred \n",
    "    in adjacent segments for target week and lags as defined in format_crash_data\n",
    "    \"\"\" \n",
    "    lag_data = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', target_week, target_year)\n",
    "    merge_lags = adj_mat.merge(lag_data, left_on='segment_id_y', right_on='segment_id', how='left')\n",
    "    adj_lags = merge_lags.groupby(['segment_id_x'])['pre_week', 'pre_month', 'pre_quarter'].sum()\n",
    "    return adj_lags\n",
    "\n",
    "adj_lags = get_adj_crash_lags(19, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill those with only self-adj zero\n",
    "adj_lags.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model = data_model.merge(adj_lags, how='left', left_on='segment_id', right_index=True, suffixes=('', '_adj'))\n",
    "data_model.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize for LR\n",
    "from sklearn.preprocessing import scale\n",
    "data_scaled = pd.DataFrame(scale(data_model[features]), \n",
    "                          columns=[f+'_scaled' for f in features])\n",
    "data_model = pd.concat([data_model, data_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning\n",
    "This uses the model helpers above.  They're based on sklearn and implement a randomized grid search with K-fold crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train obs: 2367\n",
      "Test obs: 1011\n"
     ]
    }
   ],
   "source": [
    "#Initialize data\n",
    "df = Indata(data_model, 'target')\n",
    "#Create train/test split\n",
    "df.tr_te_split(.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters for model\n",
    "#Model parameters\n",
    "params = dict()\n",
    "\n",
    "#cv parameters\n",
    "cvp = dict()\n",
    "cvp['pmetric'] = 'roc_auc'\n",
    "cvp['iter'] = 5 #number of iterations\n",
    "cvp['folds'] = 5 #folds for cv (default)\n",
    "\n",
    "#LR parameters\n",
    "mp = dict()\n",
    "mp['LogisticRegression'] = dict()\n",
    "mp['LogisticRegression']['penalty'] = ['l1','l2']\n",
    "mp['LogisticRegression']['C'] = ss.beta(a=5,b=2) #beta distribution for selecting reg strength\n",
    "mp['LogisticRegression']['class_weight'] = ['balanced']\n",
    "\n",
    "#RF model parameters\n",
    "mp['RandomForestClassifier'] = dict()\n",
    "mp['RandomForestClassifier']['n_estimators'] = [2**8] #number of trees in the forest\n",
    "mp['RandomForestClassifier']['max_features'] = ss.beta(a=5,b=2) #number of features at split\n",
    "mp['RandomForestClassifier']['max_leaf_nodes'] = [100]#ss.nbinom(n=2,p=0.001,loc=100) #max number of leaves to create\n",
    "mp['RandomForestClassifier']['class_weight'] = ['balanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Features\n",
    "features = [u'pre_week', u'pre_month', u'pre_quarter', 'avg_week', u'AADT', u'SPEEDLIMIT',\n",
    "            u'Struct_Cnd', u'Surface_Tp', u'F_F_Class', u'pre_week_adj', \n",
    "            u'pre_month_adj', u'pre_quarter_adj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize tuner\n",
    "tune = Tuner(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   32.8s finished\n"
     ]
    }
   ],
   "source": [
    "#Base RF model\n",
    "tune.tune('RF_base', 'RandomForestClassifier', features, cvp, mp['RandomForestClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "#Base LR model\n",
    "tune.tune('LR_base', 'LogisticRegression', data_scaled.columns.tolist(), cvp, mp['LogisticRegression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>params</th>\n",
       "      <th>name</th>\n",
       "      <th>m_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.635994</td>\n",
       "      <td>0.995868</td>\n",
       "      <td>{u'max_features': 0.389196245251, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.651383</td>\n",
       "      <td>0.995638</td>\n",
       "      <td>{u'max_features': 0.613217094246, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.632742</td>\n",
       "      <td>0.996014</td>\n",
       "      <td>{u'max_features': 0.833420505488, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.654406</td>\n",
       "      <td>0.995925</td>\n",
       "      <td>{u'max_features': 0.595902600931, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.631697</td>\n",
       "      <td>0.995871</td>\n",
       "      <td>{u'max_features': 0.667780932224, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.645893</td>\n",
       "      <td>0.726176</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.705986815718, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.645853</td>\n",
       "      <td>0.726174</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.586447486838, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.645977</td>\n",
       "      <td>0.726112</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.554174723574, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.645966</td>\n",
       "      <td>0.726531</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.846027150078, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.646151</td>\n",
       "      <td>0.726500</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.88057896213, u'cla...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  mean_train_score  \\\n",
       "0         0.635994          0.995868   \n",
       "1         0.651383          0.995638   \n",
       "2         0.632742          0.996014   \n",
       "3         0.654406          0.995925   \n",
       "4         0.631697          0.995871   \n",
       "0         0.645893          0.726176   \n",
       "1         0.645853          0.726174   \n",
       "2         0.645977          0.726112   \n",
       "3         0.645966          0.726531   \n",
       "4         0.646151          0.726500   \n",
       "\n",
       "                                              params     name  \\\n",
       "0  {u'max_features': 0.389196245251, u'max_leaf_n...  RF_base   \n",
       "1  {u'max_features': 0.613217094246, u'max_leaf_n...  RF_base   \n",
       "2  {u'max_features': 0.833420505488, u'max_leaf_n...  RF_base   \n",
       "3  {u'max_features': 0.595902600931, u'max_leaf_n...  RF_base   \n",
       "4  {u'max_features': 0.667780932224, u'max_leaf_n...  RF_base   \n",
       "0  {u'penalty': u'l2', u'C': 0.705986815718, u'cl...  LR_base   \n",
       "1  {u'penalty': u'l1', u'C': 0.586447486838, u'cl...  LR_base   \n",
       "2  {u'penalty': u'l1', u'C': 0.554174723574, u'cl...  LR_base   \n",
       "3  {u'penalty': u'l1', u'C': 0.846027150078, u'cl...  LR_base   \n",
       "4  {u'penalty': u'l1', u'C': 0.88057896213, u'cla...  LR_base   \n",
       "\n",
       "                   m_name  \n",
       "0  RandomForestClassifier  \n",
       "1  RandomForestClassifier  \n",
       "2  RandomForestClassifier  \n",
       "3  RandomForestClassifier  \n",
       "4  RandomForestClassifier  \n",
       "0      LogisticRegression  \n",
       "1      LogisticRegression  \n",
       "2      LogisticRegression  \n",
       "3      LogisticRegression  \n",
       "4      LogisticRegression  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display results\n",
    "tune.grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RF_base model with 12 features\n",
      "f1_score:  0.0\n",
      "brier_score:  0.0215573952264\n",
      "AUC score:  0.494994994995\n",
      "Confusion Matrix:  [[989  10]\n",
      " [ 12   0]]\n",
      "Fitting LR_base model with 12 features\n",
      "f1_score:  0.0444444444444\n",
      "brier_score:  0.203363491209\n",
      "AUC score:  0.623873873874\n",
      "Confusion Matrix:  [[747 252]\n",
      " [  6   6]]\n"
     ]
    }
   ],
   "source": [
    "# Run test\n",
    "test = Tester(df)\n",
    "test.init_tuned(tune)\n",
    "test.run_tuned('RF_base', cal=False)\n",
    "test.run_tuned('LR_base', cal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'AADT', 0.35615405664948058), ('avg_week', 0.2808856808158679), (u'SPEEDLIMIT', 0.12822782182676984), (u'Struct_Cnd', 0.1057143126098706), (u'F_F_Class', 0.045649454090312416), (u'pre_quarter', 0.036436559482359333), (u'Surface_Tp', 0.027628125151329751), (u'pre_month', 0.015104806651960005), (u'pre_week', 0.0041991827220493709)]\n"
     ]
    }
   ],
   "source": [
    "# Check feature importance\n",
    "f_importance = tune.best_models['RF_base']['m_fit'].feature_importances_\n",
    "fi = list(zip(features, f_importance))\n",
    "print sorted(fi, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift chart by \"risk bin\"\n",
    "The classifier problem is difficult because the classes are unbalanced (.05% have crashes at target week).  More useful are the probabilities being produced by the model, which give some idea of risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lift_chart(x_col, y_col, data, ax=None):\n",
    "\n",
    "    p = sns.barplot(x=x_col, y=y_col, data=data, \n",
    "                    palette='Reds', ax = None, ci=None)\n",
    "    vals = p.get_yticks()\n",
    "    p.set_yticklabels(['{:3.0f}%'.format(i*100) for i in vals])\n",
    "    xvals = [x.get_text().split(',')[-1].strip(']') for x in p.get_xticklabels()]\n",
    "    xvals = ['{:3.0f}%'.format(float(x)*100) for x in xvals]\n",
    "    p.set_xticklabels(xvals)\n",
    "    p.set_facecolor('white')\n",
    "    p.set_xlabel('')\n",
    "    p.set_ylabel('')\n",
    "    p.set_title('Predicted probability vs actual percent')\n",
    "    return(p)\n",
    "    \n",
    "def density(data, score, ax=None):\n",
    "    p = sns.kdeplot(risk_df['risk_score'], ax=ax)\n",
    "    p.set_facecolor('white')\n",
    "    p.legend('')\n",
    "    p.set_xlabel('Predicted probability of crash')\n",
    "    p.set_title('KDE plot predictions')\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1011.000000\n",
      "mean        0.984928\n",
      "std         0.052679\n",
      "min         0.173463\n",
      "25%         0.986495\n",
      "50%         1.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: risk_score, dtype: float64\n",
      "categories\n",
      "(-1, 0]            0\n",
      "(0, 0.01]          0\n",
      "(0.01, 0.02]       0\n",
      "(0.02, 0.05]       0\n",
      "(0.05, 1]       1011\n",
      "Name: crash, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "risk_scores = test.rundict['LR_base']['m_fit'].predict_proba(test.data.test_x[features])[:,1]\n",
    "risk_df = pd.DataFrame({'risk_score':risk_scores, 'crash':test.data.test_y})\n",
    "print risk_df.risk_score.describe()\n",
    "risk_df['categories'] = pd.cut(risk_df['risk_score'], bins=[-1, 0, .01, .02, .05, max(risk_scores)])\n",
    "risk_mean = risk_df.groupby('categories')['crash'].count()\n",
    "print risk_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10f54be50>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAFlCAYAAABFk4l1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111a46c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "lift_chart('categories', 'crash', risk_df, \n",
    "           ax=axes[1])\n",
    "density(risk_df, 'risk_score', ax=axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output predictions\n",
    "# predict on all segments\n",
    "data_model['risk_score'] = test.rundict['RF_base']['m_fit'].predict_proba(data_model[features])[:,1]\n",
    "data_model.to_csv('seg_with_risk_score_adj.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sensitivity to week\n",
    "I predicted an arbitrary week as target here, but I'd like to see whether things change significantly if I change that week.  A good metric to measure that is brier score loss.  It'll be low throughout as the classifier doesn't perform great, but it shouldn't vary a huge amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_for_week(weeks=[20, 30, 40, 50], output=False):\n",
    "    for w in [20, 30, 40, 50]:\n",
    "        print \"week \", w\n",
    "        crash_lags = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', w, 2016)\n",
    "        data = crash_lags.merge(data_segs, left_on='segment_id', right_on='segment_id')\n",
    "        adj_lags = get_adj_crash_lags(w, 2016)\n",
    "        data = data.merge(adj_lags, left_on='segment_id', right_index=True, suffixes=('', '_adj'))\n",
    "        data.fillna(0, inplace=True)\n",
    "        df = Indata(data, 'target')\n",
    "        # create train/test split\n",
    "        df.tr_te_split(.7)\n",
    "        test = Tester(df)\n",
    "        test.init_tuned(tune)\n",
    "        test.run_tuned('LR_base', cal=False)\n",
    "        print '\\n'\n",
    "    if output==True:\n",
    "        return(test.rundict['LR_base']['m_fit'].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week  20\n",
      "Train obs: 2367\n",
      "Test obs: 1011\n",
      "Fitting LR_base model with 12 features\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"[u'pre_week_scaled' u'pre_month_scaled' u'pre_quarter_scaled'\\n 'avg_week_scaled' u'AADT_scaled' u'SPEEDLIMIT_scaled' u'Struct_Cnd_scaled'\\n u'Surface_Tp_scaled' u'F_F_Class_scaled' u'pre_week_adj_scaled'\\n u'pre_month_adj_scaled' u'pre_quarter_adj_scaled'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-78ff6e31933f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_model_for_week\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-9c5526570564>\u001b[0m in \u001b[0;36mrun_model_for_week\u001b[0;34m(weeks, output)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LR_base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e9484aaf2483>\u001b[0m in \u001b[0;36mrun_tuned\u001b[0;34m(self, name, cal, cal_m)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m#Run from tuned set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_m\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrundict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrundict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m#Output rundict to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e9484aaf2483>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, name, model, features, cal, cal_m)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mcal_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mrnd_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[u'pre_week_scaled' u'pre_month_scaled' u'pre_quarter_scaled'\\n 'avg_week_scaled' u'AADT_scaled' u'SPEEDLIMIT_scaled' u'Struct_Cnd_scaled'\\n u'Surface_Tp_scaled' u'F_F_Class_scaled' u'pre_week_adj_scaled'\\n u'pre_month_adj_scaled' u'pre_quarter_adj_scaled'] not in index\""
     ]
    }
   ],
   "source": [
    "run_model_for_week()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# week predictions output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
