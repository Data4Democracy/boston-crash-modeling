{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model for crash prediction\n",
    "### Developed by: bpben\n",
    "#### Details steps of data processing, feature engineering and model tuning/testing for crash and road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers for tuning/testing models, available [here](https://github.com/bpben/model_helpers) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble as ske\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn import metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import model_selection as cv\n",
    "\n",
    "class Indata():\n",
    "    scoring = None\n",
    "    data = None\n",
    "    train_x, train_y, test_x, test_y = None, None, None, None\n",
    "    is_split = 0\n",
    "    \n",
    "    #init with pandas DF and target column name, specify scoring observations\n",
    "    def __init__(self, data, target, scoring=None):\n",
    "        #If scoring observations, store under scoring attribute\n",
    "        if scoring is not None:\n",
    "            self.data = data[~(scoring)]\n",
    "            self.scoring = data[scoring]\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.target = target\n",
    "    \n",
    "    # Split into train/test\n",
    "    # pct = percent training observations\n",
    "    # datesort = specify date column for sorting values\n",
    "    #   If this is not None, split will be non-random (i.e. split on sorted obs)\n",
    "    def tr_te_split(self, pct, datesort=None):\n",
    "        if datesort:\n",
    "            self.data.sort_values(datesort, inplace=True)\n",
    "            self.data.reset_index(drop=True, inplace=True)\n",
    "            inds = np.arange(0.0,len(self.data)) / len(self.data) < pct\n",
    "        else:\n",
    "            inds = np.random.rand(len(self.data)) < pct\n",
    "        self.train_x = self.data[inds]\n",
    "        print 'Train obs:', len(self.train_x)\n",
    "        self.train_y = self.data[self.target][inds]\n",
    "        self.test_x = self.data[~inds]\n",
    "        print 'Test obs:', len(self.test_x)\n",
    "        self.test_y = self.data[self.target][~inds]\n",
    "        self.is_split = 1\n",
    "        \n",
    "class Tuner():\n",
    "    \"\"\"\n",
    "    Initiates with indata class, will tune series of models according to parameters.  \n",
    "    Outputs RandomizedGridCV results and parameterized model in dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    data = None\n",
    "    train_x, train_y = None, None\n",
    "    \n",
    "    def __init__(self, indata, best_models=None, grid_results=None):\n",
    "        if indata.is_split == 0:\n",
    "            raise ValueError('Data is not split, cannot be tested')\n",
    "        else:\n",
    "            self.data = indata.data\n",
    "            self.train_x = indata.train_x\n",
    "            self.train_y = indata.train_y\n",
    "            if best_models is None:\n",
    "                self.best_models = {}\n",
    "            if grid_results is None:\n",
    "                self.grid_results = pd.DataFrame()\n",
    "        \n",
    "            \n",
    "    def make_grid(self, model, obs, cvparams, mparams):\n",
    "        #Makes CV grid\n",
    "        grid = RandomizedSearchCV(\n",
    "                    model(),scoring=cvparams['pmetric'], \n",
    "                    cv = cv.KFold(cvparams['folds']), \n",
    "                    refit=False, n_iter=cvparams['iter'],\n",
    "                    param_distributions=mparams, verbose=1)\n",
    "        return(grid)\n",
    "    \n",
    "    def run_grid(self, grid, train_x, train_y):\n",
    "        grid.fit(train_x, train_y)\n",
    "        results = pd.DataFrame(grid.cv_results_)[['mean_test_score','mean_train_score','params']]\n",
    "        best = {}\n",
    "        best['bp'] = grid.best_params_\n",
    "        best[grid.scoring] = grid.best_score_\n",
    "        return(best, results)\n",
    "            \n",
    "    def tune(self, name, m_name, features, cvparams, mparams):\n",
    "        if hasattr(ske, m_name):\n",
    "            model = getattr(ske, m_name)\n",
    "        elif hasattr(skl, m_name):\n",
    "            model = getattr(skl, m_name)\n",
    "        else:\n",
    "            raise ValueError('Model name is invalid.')\n",
    "        grid = self.make_grid(model, len(self.train_x), cvparams, mparams)\n",
    "        best, results = self.run_grid(grid, self.train_x[features], self.train_y)\n",
    "        results['name'] = name\n",
    "        results['m_name'] = m_name\n",
    "        self.grid_results = self.grid_results.append(results)\n",
    "        best['model'] = model(**best['bp'])\n",
    "        best['features'] = list(features)\n",
    "        self.best_models.update({name: best}) \n",
    "        \n",
    "class Tester():\n",
    "    \"\"\"\n",
    "    Initiates with indata class, receives parameterized sklearn models, prints and stores results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, rundict=None):\n",
    "        if data.is_split == 0 :\n",
    "            raise ValueError('Data is not split, cannot be tested')\n",
    "        else:\n",
    "            self.data = data\n",
    "            if rundict is None:\n",
    "                self.rundict = {}\n",
    "            \n",
    "    #Add tuner object, will populate rundict with names, models, feature\n",
    "    def init_tuned(self, tuned):\n",
    "        if tuned.best_models=={}:\n",
    "            raise ValueError('No tuned models found')\n",
    "        else:\n",
    "            self.rundict.update(tuned.best_models)\n",
    "    \n",
    "    #Produce predicted class and probabilities\n",
    "    def predsprobs(self, model, test_x):\n",
    "        preds = model.predict(test_x)\n",
    "        probs = model.predict_proba(test_x)[:,1]\n",
    "        return(preds, probs)\n",
    "    \n",
    "    #Produce metrics\n",
    "    def get_metrics(self, preds, probs, test_y):\n",
    "        f1_s = metrics.f1_score(test_y, preds)\n",
    "        brier = metrics.brier_score_loss(test_y, probs)\n",
    "        auc = metrics.roc_auc_score(test_y, preds)\n",
    "        c_matrix = metrics.confusion_matrix(test_y, preds)\n",
    "        return(f1_s, brier, auc, c_matrix)\n",
    "    \n",
    "    #Run production, output dictionary\n",
    "    def make_result(self, model, test_x, test_y):\n",
    "        preds, probs = self.predsprobs(model, test_x)\n",
    "        f1_s, brier, auc, c_matrix = self.get_metrics(preds, probs, test_y)\n",
    "        print \"f1_score: \", f1_s\n",
    "        print \"brier_score: \", brier\n",
    "        print \"AUC score: \", auc\n",
    "        print \"Confusion Matrix: \", c_matrix\n",
    "        result = {}\n",
    "        #result['preds'] = [int(i) for i in preds]\n",
    "        #result['probs'] = [float(i) for i in probs]\n",
    "        result['f1_s'] = f1_s\n",
    "        result['brier'] = brier\n",
    "        result['auc'] = auc\n",
    "        result['c_matrix'] = c_matrix\n",
    "        return(result)\n",
    "\n",
    "    # Run model - Specify model, with parameters, features\n",
    "    # Stores it to rundict, can later be output\n",
    "    # Will overwrite previous run if name is not different\n",
    "    def run_model(self, name, model, features, cal=True, cal_m='sigmoid'):\n",
    "        results = {}\n",
    "        results['features'] = list(features)\n",
    "        print \"Fitting {} model with {} features\".format(name, len(features))\n",
    "        if cal:\n",
    "            # Need disjoint calibration/training datasets\n",
    "            # Split 50/50\n",
    "            rnd_ind = np.random.rand(len(self.data.train_x)) < .5\n",
    "            train_x = self.data.train_x[features][rnd_ind]\n",
    "            train_y = self.data.train_y[rnd_ind]\n",
    "            cal_x = self.data.train_x[features][~rnd_ind]\n",
    "            cal_y = self.data.train_y[~rnd_ind]\n",
    "        else:\n",
    "            train_x = self.data.train_x[features]\n",
    "            train_y = self.data.train_y\n",
    "\n",
    "        m_fit = model.fit(train_x, train_y)\n",
    "        result = self.make_result(\n",
    "            m_fit,\n",
    "            self.data.test_x[features],\n",
    "            self.data.test_y)\n",
    "\n",
    "        results['raw'] = result\n",
    "        results['m_fit'] = m_fit\n",
    "        if cal:\n",
    "            print \"calibrated:\"\n",
    "            m_c = CalibratedClassifierCV(m_fit, method = cal_m, cv='prefit')\n",
    "            m_fit_c = m_c.fit(cal_x, cal_y)\n",
    "            result_c = self.make_result(m_fit_c, self.data.test_x[features], self.data.test_y)\n",
    "            results['calibrated'] = result_c              \n",
    "            print \"\\n\"\n",
    "        if name in self.rundict:\n",
    "            self.rundict[name].update(results)\n",
    "        else:\n",
    "            self.rundict.update({name:results})\n",
    "    \n",
    "    #Run from tuned set\n",
    "    def run_tuned(self, name, cal=True, cal_m='sigmoid'):\n",
    "        self.run_model(name, self.rundict[name]['model'], self.rundict[name]['features'], cal, cal_m)\n",
    "    \n",
    "    #Output rundict to csv\n",
    "    def to_csv(self):\n",
    "        if self.rundict == {}:\n",
    "            raise ValueError('No results found')\n",
    "        else:\n",
    "            now = pd.to_datetime('today').value\n",
    "            #Make dataframe, transpose so each row = model\n",
    "            pd.DataFrame(self.rundict).T.to_csv('results_{}.csv'.format(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "The approach here is to create 3 time-lag features:\n",
    "\n",
    "1. crashes in the past week\n",
    "2. crashes in the past month\n",
    "3. crashes in the past quarter (three months)\n",
    "4. average crashes per week up to target week\n",
    "\n",
    "All features except 4 are calculated to exclude one another.  That is, crashes in the past month does not include the past week's crashes.  Crashes in the past quarter do not include the past month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEG_CHARS = ['AADT', 'SPEEDLIMIT', 'Struct_Cnd', 'Surface_Tp', 'F_F_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('../../data/processed/vz_predict_dataset.csv.gz', compression='gzip', dtype={'segment_id':'str'})\n",
    "data.sort_values(['segment_id', 'week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get segments with non-zero crashes\n",
    "data_nonzero = data.set_index('segment_id').loc[data.groupby('segment_id').crash.sum()>0]\n",
    "data_nonzero.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_crash_data(data, col, target):\n",
    "    \"\"\" formats crash data for train/test \n",
    "    target: week to predict (make into binary target)\n",
    "        must be >4 months in\n",
    "    gets previous week count, previous month count, previous quarter count, avg per week\n",
    "    \n",
    "    \"\"\"\n",
    "    assert target>16\n",
    "    pre_week = target - 1\n",
    "    pre_month = range(pre_week-4, target)\n",
    "    pre_quarter = range(pre_month[0]-12, target)\n",
    "    all_prior_weeks = range(1, target)\n",
    "    \n",
    "    # week interval for each segment\n",
    "    # full range = pre_quarter : target\n",
    "    sliced = data.loc[(slice(None),slice(1, target)),:]\n",
    "    week_data = sliced[col].unstack(1)\n",
    "    week_data.reset_index(level=1, inplace=True)\n",
    "    \n",
    "    # aggregate\n",
    "    week_data['pre_month'] = week_data[pre_month].sum(axis=1)\n",
    "    week_data['pre_quarter'] = week_data[pre_quarter].sum(axis=1)\n",
    "    week_data['pre_week'] = week_data[pre_week]\n",
    "    # avg as of target week\n",
    "    week_data['avg_week'] = week_data[all_prior_weeks].apply(\n",
    "        lambda x: x.sum() / len(all_prior_weeks), axis=1\n",
    "    )\n",
    "    \n",
    "    # binarize target\n",
    "    week_data['target'] = (week_data[target]>0).astype(int)\n",
    "    \n",
    "    return(week_data[['segment_id','target', 'pre_week', \n",
    "                      'pre_month', 'pre_quarter', 'avg_week']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arbitrarily choosing week = 50\n",
    "crash_lags = format_crash_data(data_nonzero.set_index(['segment_id','week']), 'crash', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_segs = data_nonzero.groupby('segment_id')[SEG_CHARS].max()  # grab the highest values from each column for a segment, not used in model?\n",
    "data_segs.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model = crash_lags.merge(data_segs, left_on='segment_id', right_on='segment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pre_week</th>\n",
       "      <th>pre_month</th>\n",
       "      <th>pre_quarter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_id_x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0010194</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010205</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010225</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0010257</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001026</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              target  pre_week  pre_month  pre_quarter\n",
       "segment_id_x                                          \n",
       "0010194            0       0.0        1.0          3.0\n",
       "0010205            0       0.0        0.0          2.0\n",
       "0010225            0       0.0        0.0          3.0\n",
       "0010257            1       0.0        0.0          1.0\n",
       "001026             0       0.0        0.0          0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in adjacency info\n",
    "adj_info = pd.read_csv('../../data/processed/adjacency_info.csv', usecols=['segment_id', 'orig_id'],\n",
    "                       dtype={'segment_id':'str', 'orig_id':'str'})\n",
    "\n",
    "# get adjacencies between segments rather than between segments and orig_id\n",
    "adj_info = adj_info[adj_info.segment_id.isin(data_model.segment_id)] # filter down to segments with crashes to keep dataset small\n",
    "adj_mat = adj_info.merge(adj_info, on='orig_id')\n",
    "adj_mat = adj_mat[['segment_id_x', 'segment_id_y']]\n",
    "adj_mat.drop_duplicates(inplace=True)\n",
    "adj_mat = adj_mat[adj_mat.segment_id_x != adj_mat.segment_id_y]\n",
    "\n",
    "def get_adj_crash_lags(target_week):\n",
    "    \"\"\"calculate total number of crashes that occurred \n",
    "    in adjacent segments for target week and lags as defined in format_crash_data\n",
    "    \"\"\" \n",
    "    lag_data = format_crash_data(data_nonzero.set_index(['segment_id','week']), 'crash', target_week)\n",
    "    merge_lags = adj_mat.merge(lag_data, left_on='segment_id_y', right_on='segment_id')\n",
    "    adj_lags = merge_lags.groupby(['segment_id_x'])['target', 'pre_week', 'pre_month', 'pre_quarter'].sum()\n",
    "    return adj_lags\n",
    "\n",
    "adj_lags = get_adj_crash_lags(50)\n",
    "adj_lags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>target</th>\n",
       "      <th>pre_week</th>\n",
       "      <th>pre_month</th>\n",
       "      <th>pre_quarter</th>\n",
       "      <th>avg_week</th>\n",
       "      <th>AADT</th>\n",
       "      <th>SPEEDLIMIT</th>\n",
       "      <th>Struct_Cnd</th>\n",
       "      <th>Surface_Tp</th>\n",
       "      <th>F_F_Class</th>\n",
       "      <th>target_adj</th>\n",
       "      <th>pre_week_adj</th>\n",
       "      <th>pre_month_adj</th>\n",
       "      <th>pre_quarter_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010194</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>9909</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0010205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>9850</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0010225</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>197004</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0010257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>23823</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001026</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  segment_id  target  pre_week  pre_month  pre_quarter  avg_week    AADT  \\\n",
       "2    0010194       0       1.0        1.0          1.0  0.020408    9909   \n",
       "3    0010205       0       0.0        0.0          1.0  0.020408    9850   \n",
       "4    0010225       0       0.0        0.0          1.0  0.061224  197004   \n",
       "5    0010257       0       0.0        0.0          0.0  0.020408   23823   \n",
       "6     001026       0       0.0        0.0          0.0  0.020408       0   \n",
       "\n",
       "   SPEEDLIMIT  Struct_Cnd  Surface_Tp  F_F_Class  target_adj  pre_week_adj  \\\n",
       "2          30           2           6          4           0           0.0   \n",
       "3          25           2           6          4           0           0.0   \n",
       "4          65           2           6          1           0           0.0   \n",
       "5          15           2           6          3           1           0.0   \n",
       "6          25           1           5          7           0           0.0   \n",
       "\n",
       "   pre_month_adj  pre_quarter_adj  \n",
       "2            1.0              3.0  \n",
       "3            0.0              2.0  \n",
       "4            0.0              3.0  \n",
       "5            0.0              1.0  \n",
       "6            0.0              0.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model = data_model.merge(adj_lags, left_on='segment_id', right_index=True, suffixes=('', '_adj'))\n",
    "data_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning\n",
    "This uses the model helpers above.  They're based on sklearn and implement a randomized grid search with K-fold crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train obs: 892\n",
      "Test obs: 419\n"
     ]
    }
   ],
   "source": [
    "#Initialize data\n",
    "#Fill missing 0 (Only affects tot_crash)\n",
    "df = Indata(data_model, 'target')\n",
    "#Create train/test split\n",
    "df.tr_te_split(.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters for model\n",
    "#Model parameters\n",
    "params = dict()\n",
    "\n",
    "#cv parameters\n",
    "cvp = dict()\n",
    "cvp['pmetric'] = 'roc_auc'\n",
    "cvp['iter'] = 5 #number of iterations\n",
    "cvp['folds'] = 5 #folds for cv (default)\n",
    "\n",
    "#LR parameters\n",
    "mp = dict()\n",
    "mp['LogisticRegression'] = dict()\n",
    "mp['LogisticRegression']['penalty'] = ['l1','l2']\n",
    "mp['LogisticRegression']['C'] = ss.beta(a=5,b=2) #beta distribution for selecting reg strength\n",
    "\n",
    "#RF model parameters\n",
    "mp['RandomForestClassifier'] = dict()\n",
    "mp['RandomForestClassifier']['n_estimators'] = [2**8] #number of trees in the forest\n",
    "mp['RandomForestClassifier']['max_features'] = ss.beta(a=5,b=2) #number of features at split\n",
    "mp['RandomForestClassifier']['max_leaf_nodes'] = ss.nbinom(n=2,p=0.001,loc=100) #max number of leaves to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "features = [u'pre_week', u'pre_month', u'pre_quarter', 'avg_week', u'AADT', u'SPEEDLIMIT',\n",
    "            u'Struct_Cnd', u'Surface_Tp', u'F_F_Class', u'target_adj', u'pre_week_adj', \n",
    "            u'pre_month_adj', u'pre_quarter_adj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize tuner\n",
    "tune = Tuner(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:   21.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Base RF model\n",
    "tune.tune('RF_base', 'RandomForestClassifier', features, cvp, mp['RandomForestClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "#Base LR model\n",
    "tune.tune('LR_base', 'LogisticRegression', features, cvp, mp['LogisticRegression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>params</th>\n",
       "      <th>name</th>\n",
       "      <th>m_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.726749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{u'max_features': 0.847569165727, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.712698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{u'max_features': 0.823964551884, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.740453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{u'max_features': 0.541304287056, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.733499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{u'max_features': 0.779063630296, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.737557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{u'max_features': 0.832806203804, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.650387</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.792376387828}</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.514973</td>\n",
       "      <td>0.638262</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.829996188827}</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.534575</td>\n",
       "      <td>0.644985</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.618871203626}</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.512326</td>\n",
       "      <td>0.656116</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.872956806622}</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.514973</td>\n",
       "      <td>0.637983</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.767341652723}</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  mean_train_score  \\\n",
       "0         0.726749          1.000000   \n",
       "1         0.712698          1.000000   \n",
       "2         0.740453          1.000000   \n",
       "3         0.733499          1.000000   \n",
       "4         0.737557          1.000000   \n",
       "0         0.521362          0.650387   \n",
       "1         0.514973          0.638262   \n",
       "2         0.534575          0.644985   \n",
       "3         0.512326          0.656116   \n",
       "4         0.514973          0.637983   \n",
       "\n",
       "                                              params     name  \\\n",
       "0  {u'max_features': 0.847569165727, u'max_leaf_n...  RF_base   \n",
       "1  {u'max_features': 0.823964551884, u'max_leaf_n...  RF_base   \n",
       "2  {u'max_features': 0.541304287056, u'max_leaf_n...  RF_base   \n",
       "3  {u'max_features': 0.779063630296, u'max_leaf_n...  RF_base   \n",
       "4  {u'max_features': 0.832806203804, u'max_leaf_n...  RF_base   \n",
       "0          {u'penalty': u'l1', u'C': 0.792376387828}  LR_base   \n",
       "1          {u'penalty': u'l2', u'C': 0.829996188827}  LR_base   \n",
       "2          {u'penalty': u'l1', u'C': 0.618871203626}  LR_base   \n",
       "3          {u'penalty': u'l1', u'C': 0.872956806622}  LR_base   \n",
       "4          {u'penalty': u'l2', u'C': 0.767341652723}  LR_base   \n",
       "\n",
       "                   m_name  \n",
       "0  RandomForestClassifier  \n",
       "1  RandomForestClassifier  \n",
       "2  RandomForestClassifier  \n",
       "3  RandomForestClassifier  \n",
       "4  RandomForestClassifier  \n",
       "0      LogisticRegression  \n",
       "1      LogisticRegression  \n",
       "2      LogisticRegression  \n",
       "3      LogisticRegression  \n",
       "4      LogisticRegression  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display results\n",
    "tune.grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RF_base model with 13 features\n",
      "f1_score:  0.181818181818\n",
      "brier_score:  0.0415453489754\n",
      "AUC score:  0.55\n",
      "Confusion Matrix:  [[399   0]\n",
      " [ 18   2]]\n"
     ]
    }
   ],
   "source": [
    "# Run test\n",
    "test = Tester(df)\n",
    "test.init_tuned(tune)\n",
    "test.run_tuned('RF_base', cal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'pre_month', 0.037463528723878543), (u'pre_quarter', 0.049241071252002368), ('avg_week', 0.18248892009012666), (u'AADT', 0.32389796686789779), (u'SPEEDLIMIT', 0.074509579984432028), (u'Struct_Cnd', 0.084360396874757007), (u'Surface_Tp', 0.036514782566124927), (u'F_F_Class', 0.042051340309414015), (u'pre_month_adj', 0.039469311330185775), (u'pre_quarter_adj', 0.12018617428920014)]\n"
     ]
    }
   ],
   "source": [
    "# View feature importance - is adding adjacency matrix worth it?\n",
    "#print tune.__dict__\n",
    "f_importance = tune.best_models['RF_base']['m_fit'].feature_importances_\n",
    "#print tune.best_models['RF_base']['model'].feature_importances_\n",
    "fi = list(zip(features, f_importance))\n",
    "# kind of? all features have small importances\n",
    "print [x for x in fi if x[1] > 0.01]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift chart by \"risk bin\"\n",
    "The classifier problem is difficult because the classes are unbalanced (.05% have crashes at target week).  More useful are the probabilities being produced by the model, which give some idea of risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lift_chart(x_col, y_col, data, ax=None):\n",
    "\n",
    "    p = sns.barplot(x=x_col, y=y_col, data=data, \n",
    "                    palette='Reds', ax = None, ci=None)\n",
    "    vals = p.get_yticks()\n",
    "    p.set_yticklabels(['{:3.0f}%'.format(i*100) for i in vals])\n",
    "    xvals = [x.get_text().split(',')[-1].strip(']') for x in p.get_xticklabels()]\n",
    "    xvals = ['{:3.0f}%'.format(float(x)*100) for x in xvals]\n",
    "    p.set_xticklabels(xvals)\n",
    "    p.set_axis_bgcolor('white')\n",
    "    p.set_xlabel('')\n",
    "    p.set_ylabel('')\n",
    "    p.set_title('Predicted probability vs actual percent')\n",
    "    return(p)\n",
    "    \n",
    "def density(data, score, ax=None):\n",
    "    p = sns.kdeplot(risk_df['risk_score'], ax=ax)\n",
    "    p.set_axis_bgcolor('white')\n",
    "    p.legend('')\n",
    "    p.set_xlabel('Predicted probability of crash')\n",
    "    p.set_title('KDE plot predictions')\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    419.000000\n",
      "mean       0.026700\n",
      "std        0.082360\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.011719\n",
      "max        0.695312\n",
      "Name: risk_score, dtype: float64\n",
      "categories\n",
      "(-1, 0]          247\n",
      "(0, 0.01]         64\n",
      "(0.01, 0.02]      36\n",
      "(0.02, 0.05]      30\n",
      "(0.05, 0.695]     42\n",
      "Name: crash, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "risk_scores = test.rundict['RF_base']['m_fit'].predict_proba(test.data.test_x[features])[:,1]\n",
    "risk_df = pd.DataFrame({'risk_score':risk_scores, 'crash':test.data.test_y})\n",
    "print risk_df.risk_score.describe()\n",
    "risk_df['categories'] = pd.cut(risk_df['risk_score'], bins=[-1, 0, .01, .02, .05, max(risk_scores)])\n",
    "risk_mean = risk_df.groupby('categories')['crash'].count()\n",
    "print risk_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alice\\Anaconda2\\envs\\boston-crash-model\\lib\\site-packages\\ipykernel_launcher.py:10: MatplotlibDeprecationWarning: The set_axis_bgcolor function was deprecated in version 2.0. Use set_facecolor instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Alice\\Anaconda2\\envs\\boston-crash-model\\lib\\site-packages\\ipykernel_launcher.py:18: MatplotlibDeprecationWarning: The set_axis_bgcolor function was deprecated in version 2.0. Use set_facecolor instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xf336ac8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFlCAYAAACqUeJLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxqyMiy9jjDFmZVx8GWOMMSv7HygQrGNBHZsPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf336b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "lift_chart('categories', 'crash', risk_df, \n",
    "           ax=axes[1])\n",
    "density(risk_df, 'risk_score', ax=axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output predictions\n",
    "# predict on all segments\n",
    "data_model['risk_score'] = test.rundict['RF_base']['m_fit'].predict_proba(data_model[features])[:,1]\n",
    "data_model.to_csv('seg_with_risk_score_adj.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sensitivity to week\n",
    "I predicted an arbitrary week as target here, but I'd like to see whether things change significantly if I change that week.  A good metric to measure that is brier score loss.  It'll be low throughout as the classifier doesn't perform great, but it shouldn't vary a huge amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week  20\n",
      "Train obs: 934\n",
      "Test obs: 377\n",
      "Fitting RF_base model with 13 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alice\\Anaconda2\\envs\\boston-crash-model\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.0\n",
      "brier_score:  0.0332722234973\n",
      "AUC score:  0.5\n",
      "Confusion Matrix:  [[366   0]\n",
      " [ 11   0]]\n",
      "\n",
      "\n",
      "week  30\n",
      "Train obs: 868\n",
      "Test obs: 443\n",
      "Fitting RF_base model with 13 features\n",
      "f1_score:  0.0\n",
      "brier_score:  0.0389972079302\n",
      "AUC score:  0.497668997669\n",
      "Confusion Matrix:  [[427   2]\n",
      " [ 14   0]]\n",
      "\n",
      "\n",
      "week  40\n",
      "Train obs: 921\n",
      "Test obs: 390\n",
      "Fitting RF_base model with 13 features\n",
      "f1_score:  0.0\n",
      "brier_score:  0.0304707304531\n",
      "AUC score:  0.484415584416\n",
      "Confusion Matrix:  [[373  12]\n",
      " [  5   0]]\n",
      "\n",
      "\n",
      "week  50\n",
      "Train obs: 912\n",
      "Test obs: 399\n",
      "Fitting RF_base model with 13 features\n",
      "f1_score:  0.0\n",
      "brier_score:  0.0221941839775\n",
      "AUC score:  0.497435897436\n",
      "Confusion Matrix:  [[388   2]\n",
      " [  9   0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in [20, 30, 40, 50]:\n",
    "    print \"week \", w\n",
    "    crash_lags = format_crash_data(data_nonzero.set_index(['segment_id','week']), 'crash', w)\n",
    "    data_model = crash_lags.merge(data_segs, left_on='segment_id', right_on='segment_id')\n",
    "    adj_lags = get_adj_crash_lags(w)\n",
    "    data_model = data_model.merge(adj_lags, left_on='segment_id', right_index=True, suffixes=('', '_adj'))\n",
    "    df = Indata(data_model, 'target')\n",
    "    # create train/test split\n",
    "    df.tr_te_split(.7)\n",
    "    test = Tester(df)\n",
    "    test.init_tuned(tune)\n",
    "    test.run_tuned('RF_base', cal=False)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
