{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model for crash prediction\n",
    "### Developed by: bpben\n",
    "#### Details steps of data processing, feature engineering and model tuning/testing for crash and road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers for tuning/testing models, available [here](https://github.com/bpben/model_helpers) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble as ske\n",
    "import sklearn.svm as svm\n",
    "import sklearn.linear_model as skl\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold, GroupKFold, GroupShuffleSplit\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Indata():\n",
    "    scoring = None\n",
    "    data = None\n",
    "    train_x, train_y, test_x, test_y = None, None, None, None\n",
    "    is_split = 0\n",
    "    \n",
    "    #init with pandas DF and target column name, specify scoring observations\n",
    "    def __init__(self, data, target, scoring=None):\n",
    "        #If scoring observations, store under scoring attribute\n",
    "        if scoring is not None:\n",
    "            self.data = data[~(scoring)]\n",
    "            self.scoring = data[scoring]\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.target = target\n",
    "    \n",
    "    # Split into train/test\n",
    "    # pct : percent training observations\n",
    "    # datesort : specify date column for sorting values\n",
    "    #   If this is not None, split will be non-random (i.e. split on sorted obs)\n",
    "    def tr_te_split(self, pct, datesort=None, group_col=None):\n",
    "        \"\"\"\n",
    "        Split into train/test\n",
    "        pct : percent training observations\n",
    "        datesort : specify date column for sorting values\n",
    "            If this is not None, split will be non-random (i.e. split on sorted obs)\n",
    "        group_col : group column name for groupkfold split\n",
    "            Will also be passed to tuner\n",
    "        \"\"\"\n",
    "        if group_col:\n",
    "            self.group_col = group_col\n",
    "            grouper = GroupShuffleSplit(n_splits=1, train_size=pct)\n",
    "            g = grouper.split(self.data, groups=self.data[group_col])\n",
    "            # get the actual indexes of the training set\n",
    "            inds, _ = tuple(*g)\n",
    "            # translate that into boolean array\n",
    "            inds = self.data.index[inds]\n",
    "            inds = self.data.index.isin(inds)\n",
    "        elif datesort:\n",
    "            self.data.sort_values(datesort, inplace=True)\n",
    "            self.data.reset_index(drop=True, inplace=True)\n",
    "            inds = np.arange(0.0,len(self.data)) / len(self.data) < pct\n",
    "        else:\n",
    "            inds = np.random.rand(len(self.data)) < pct\n",
    "        self.train_x = self.data[inds]\n",
    "        print 'Train obs:', len(self.train_x)\n",
    "        self.train_y = self.data[self.target][inds]\n",
    "        self.test_x = self.data[~inds]\n",
    "        print 'Test obs:', len(self.test_x)\n",
    "        self.test_y = self.data[self.target][~inds]\n",
    "        self.is_split = 1\n",
    "        \n",
    "class Tuner():\n",
    "    \"\"\"\n",
    "    Initiates with indata class, will tune series of models according to parameters.  \n",
    "    Outputs RandomizedGridCV results and parameterized model in dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    data = None\n",
    "    train_x, train_y = None, None\n",
    "    group_col = None\n",
    "    \n",
    "    def __init__(self, indata, best_models=None, grid_results=None):\n",
    "        if indata.is_split == 0:\n",
    "            raise ValueError('Data is not split, cannot be tested')\n",
    "        # check if grouped by some column\n",
    "        if hasattr(indata,'group_col'):\n",
    "            self.group_col = indata.group_col\n",
    "        self.data = indata.data\n",
    "        self.train_x = indata.train_x\n",
    "        self.train_y = indata.train_y\n",
    "        if best_models is None:\n",
    "            self.best_models = {}\n",
    "        if grid_results is None:\n",
    "            self.grid_results = pd.DataFrame()\n",
    "        \n",
    "            \n",
    "    def make_grid(self, model, cvparams, mparams):\n",
    "        #Makes CV grid\n",
    "        # to implement, no capability for GroupKFold for randomizedsearch\n",
    "        #if self.group_col:\n",
    "            #cv = GroupKFold(cvparams['folds'])\n",
    "        grid = RandomizedSearchCV(\n",
    "                    model(),scoring=cvparams['pmetric'], \n",
    "                    cv = KFold(cvparams['folds'], cvparams['shuffle']),\n",
    "                    refit=False, n_iter=cvparams['iter'],\n",
    "                    param_distributions=mparams, verbose=1)\n",
    "        return(grid)\n",
    "    \n",
    "    def run_grid(self, grid, train_x, train_y):\n",
    "        grid.fit(train_x, train_y)\n",
    "        results = pd.DataFrame(grid.cv_results_)[['mean_test_score','mean_train_score','params']]\n",
    "        best = {}\n",
    "        best['bp'] = grid.best_params_\n",
    "        best[grid.scoring] = grid.best_score_\n",
    "        return(best, results)\n",
    "            \n",
    "    def tune(self, name, m_name, features, cvparams, mparams):\n",
    "        if hasattr(ske, m_name):\n",
    "            model = getattr(ske, m_name)\n",
    "        elif hasattr(skl, m_name):\n",
    "            model = getattr(skl, m_name)\n",
    "        elif hasattr(xgb, m_name):\n",
    "            model = getattr(xgb, m_name)\n",
    "        elif hasattr(svm, m_name):\n",
    "            model = getattr(svm, m_name)\n",
    "        else:\n",
    "            raise ValueError('Model name is invalid.')\n",
    "        grid = self.make_grid(model, cvparams, mparams)\n",
    "        best, results = self.run_grid(grid, self.train_x[features], self.train_y)\n",
    "        results['name'] = name\n",
    "        results['m_name'] = m_name\n",
    "        self.grid_results = self.grid_results.append(results)\n",
    "        best['model'] = model(**best['bp'])\n",
    "        best['features'] = list(features)\n",
    "        self.best_models.update({name: best}) \n",
    "        \n",
    "class Tester():\n",
    "    \"\"\"\n",
    "    Initiates with indata class, receives parameterized sklearn models, prints and stores results\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, rundict=None):\n",
    "        if data.is_split == 0 :\n",
    "            raise ValueError('Data is not split, cannot be tested')\n",
    "        else:\n",
    "            self.data = data\n",
    "            if rundict is None:\n",
    "                self.rundict = {}\n",
    "            \n",
    "    def init_tuned(self, tuned):\n",
    "        \"\"\" pass Tuner object, populatest with names, models, features \"\"\"\n",
    "        if tuned.best_models=={}:\n",
    "            raise ValueError('No tuned models found')\n",
    "        else:\n",
    "            self.rundict.update(tuned.best_models)\n",
    "    \n",
    "    def predsprobs(self, model, test_x):\n",
    "        \"\"\" Produce predicted class and probabilities \"\"\"\n",
    "        # if the model doesn't have predict proba, will be treated as GLM\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            preds = model.predict(test_x)\n",
    "            probs = model.predict_proba(test_x)[:,1]\n",
    "        else:\n",
    "            probs = model.predict(test_x)\n",
    "            preds = (probs>=.5).astype(int)\n",
    "        return(preds, probs)\n",
    "    \n",
    "    def get_metrics(self, preds, probs, test_y):\n",
    "        \"\"\" Produce metrics (f1 score, AUC, brier) \"\"\"\n",
    "        # if test is not binary, just run brier\n",
    "        if len(np.unique(test_y))==2:\n",
    "            f1_s = metrics.f1_score(test_y, preds)\n",
    "            roc = metrics.roc_auc_score(test_y, probs)\n",
    "        else:\n",
    "            f1_s, roc = None, None\n",
    "        brier = metrics.brier_score_loss(test_y, probs)\n",
    "        return(f1_s, roc, brier)\n",
    "    \n",
    "    def make_result(self, model, test_x, test_y):\n",
    "        \"\"\" gets predictions and runs metrics \"\"\"\n",
    "        preds, probs = self.predsprobs(model, test_x)\n",
    "        f1_s, roc, brier = self.get_metrics(preds, probs, test_y)\n",
    "        print \"f1_score: \", f1_s\n",
    "        print \"roc auc: \", roc\n",
    "        print \"brier_score: \", brier\n",
    "        result = {}\n",
    "        result['f1_s'] = f1_s\n",
    "        result['roc'] = roc\n",
    "        result['brier'] = brier\n",
    "        return(result)\n",
    "\n",
    "    \n",
    "    def run_model(self, name, model, features, cal=True, cal_m='sigmoid'):\n",
    "        \"\"\"\n",
    "        Run a specific model (not from Tuner classs)\n",
    "        By default, calibrates predictions and produces metrics for them\n",
    "        Will also store in rundict object\n",
    "        \"\"\"\n",
    "\n",
    "        results = {}\n",
    "        results['features'] = list(features)\n",
    "        results['model'] = model\n",
    "        print \"Fitting {} model with {} features\".format(name, len(features))\n",
    "        if cal:\n",
    "            # Need disjoint calibration/training datasets\n",
    "            # Split 50/50\n",
    "            rnd_ind = np.random.rand(len(self.data.train_x)) < .5\n",
    "            train_x = self.data.train_x[features][rnd_ind]\n",
    "            train_y = self.data.train_y[rnd_ind]\n",
    "            cal_x = self.data.train_x[features][~rnd_ind]\n",
    "            cal_y = self.data.train_y[~rnd_ind]\n",
    "        else:\n",
    "            train_x = self.data.train_x[features]\n",
    "            train_y = self.data.train_y\n",
    "\n",
    "        m_fit = model.fit(train_x, train_y)\n",
    "        result = self.make_result(\n",
    "            m_fit,\n",
    "            self.data.test_x[features],\n",
    "            self.data.test_y)\n",
    "\n",
    "        results['raw'] = result\n",
    "        results['m_fit'] = m_fit\n",
    "        if cal:\n",
    "            print \"calibrated:\"\n",
    "            m_c = CalibratedClassifierCV(model, method = cal_m)\n",
    "            m_fit_c = m_c.fit(cal_x, cal_y)\n",
    "            result_c = self.make_result(m_fit_c, self.data.test_x[features], self.data.test_y)\n",
    "            results['calibrated'] = result_c              \n",
    "            print \"\\n\"\n",
    "        if name in self.rundict:\n",
    "            self.rundict[name].update(results)\n",
    "        else:\n",
    "            self.rundict.update({name:results})\n",
    "    \n",
    "    def run_tuned(self, name, cal=True, cal_m='sigmoid'):\n",
    "        \"\"\" Wrapper for run_model when using Tuner object \"\"\"\n",
    "        self.run_model(name, self.rundict[name]['model'], self.rundict[name]['features'], cal, cal_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "The approach here is to create 3 time-lag features:\n",
    "\n",
    "1. crashes in the past week\n",
    "2. crashes in the past month\n",
    "3. crashes in the past quarter (three months)\n",
    "4. average crashes per week up to target week\n",
    "\n",
    "All features except 4 are calculated to exclude one another.  That is, crashes in the past month does not include the past week's crashes.  Crashes in the past quarter do not include the past month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEG_CHARS = ['AADT', 'SPEEDLIMIT', 'Struct_Cnd', 'Surface_Tp', 'F_F_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('../../data/processed/vz_predict_dataset.csv.gz', compression='gzip', dtype={'segment_id':'str'})\n",
    "data.sort_values(['segment_id', 'year', 'week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get segments with non-zero crashes\n",
    "data_nonzero = data.set_index('segment_id').loc[data.groupby('segment_id').crash.sum()>0]\n",
    "data_nonzero.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_crash_data(data, col, target_week, target_year):\n",
    "    \"\"\" formats crash data for train/test \n",
    "    target_week: week to predict (make into binary target)\n",
    "    target_year: year for predicted week\n",
    "    note: data must be available for 4 months prior to target\n",
    "    gets previous week count, previous month count, previous quarter count, avg per week\n",
    "    \"\"\"\n",
    "    assert target_week>16\n",
    "    pre_week = target_week - 1\n",
    "    pre_month = range(pre_week-4, target_week)\n",
    "    pre_quarter = range(pre_month[0]-12, target_week)\n",
    "    \n",
    "    # week interval for each segment\n",
    "    # full range = pre_quarter : target\n",
    "    sliced = data.loc[(slice(None),slice(target_year,target_year), slice(1, target_week)),:]\n",
    "    week_data = sliced[col].unstack(2)\n",
    "    week_data.reset_index(level=1, inplace=True)\n",
    "    \n",
    "    # aggregate\n",
    "    week_data['pre_month'] = week_data[pre_month].sum(axis=1)\n",
    "    week_data['pre_quarter'] = week_data[pre_quarter].sum(axis=1)\n",
    "    week_data['pre_week'] = week_data[pre_week]\n",
    "\n",
    "    # avg as of target week\n",
    "    except_target = data.loc[(slice(None),\n",
    "                       slice(target_year,target_year),\n",
    "                       slice(target_week,None)),:].index\n",
    "    avg_week = data.drop(except_target)\n",
    "    avg_week = avg_week.reset_index().groupby('segment_id')[col].mean()\n",
    "    avg_week.name = 'avg_week'\n",
    "    # join to week data\n",
    "    week_data = week_data.join(avg_week)\n",
    "\n",
    "    # binarize target\n",
    "    week_data['target'] = (week_data[target_week]>0).astype(int)\n",
    "    week_data = week_data.reset_index()\n",
    "\n",
    "    return(week_data[['segment_id','target', 'pre_week',\n",
    "                      'pre_month', 'pre_quarter', 'avg_week']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple add concern, any concern reported 2016\n",
    "concern_observed = data_nonzero[data_nonzero.year==2016].groupby('segment_id').concern.max()\n",
    "concern_observed.name = 'concern_observed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crash_lags = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', 19, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_segs = data_nonzero.groupby('segment_id')[SEG_CHARS].max()  # grab the highest values from each column for a segment, not used in model?\n",
    "data_segs.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model = crash_lags.merge(data_segs, left_on='segment_id', right_on='segment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add concerns\n",
    "data_model = data_model.merge(concern_observed.reset_index(), on='segment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add in adjacency info\n",
    "adj_info = pd.read_csv('../../data/processed/adjacency_info.csv', usecols=['segment_id', 'orig_id'],\n",
    "                       dtype={'segment_id':'str', 'orig_id':'str'})\n",
    "\n",
    "# link adjacent segments for segments with crashes\n",
    "adj_info = adj_info[adj_info.segment_id.isin(data_model.segment_id)]\n",
    "adj_mat = adj_info.merge(adj_info, on='orig_id')\n",
    "adj_mat = adj_mat[['segment_id_x', 'segment_id_y']]\n",
    "adj_mat.drop_duplicates(inplace=True)\n",
    "# including segments with only self-adjacent\n",
    "# for this, need to ensure they don't join to their own data\n",
    "adj_mat.loc[adj_mat.segment_id_x==adj_mat.segment_id_y, 'segment_id_y'] = np.NaN\n",
    "\n",
    "def get_adj_crash_lags(target_week, target_year):\n",
    "    \"\"\"calculate total number of crashes that occurred \n",
    "    in adjacent segments for target week and lags as defined in format_crash_data\n",
    "    \"\"\" \n",
    "    lag_data = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', target_week, target_year)\n",
    "    merge_lags = adj_mat.merge(lag_data, left_on='segment_id_y', right_on='segment_id', how='left')\n",
    "    adj_lags = merge_lags.groupby(['segment_id_x'])['pre_week', 'pre_month', 'pre_quarter'].sum()\n",
    "    return adj_lags\n",
    "\n",
    "adj_lags = get_adj_crash_lags(19, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill those with only self-adj zero\n",
    "adj_lags.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model = data_model.merge(adj_lags, how='left', left_on='segment_id', right_index=True, suffixes=('', '_adj'))\n",
    "data_model.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize for LR\n",
    "#from sklearn.preprocessing import scale\n",
    "#data_scaled = pd.DataFrame(scale(data_model['AADT', 'SPEEDLIMIT']), \n",
    "#                          columns=[f+'_scaled' for f in features])\n",
    "#data_model = pd.concat([data_model, data_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying a different feature set\n",
    "dummy_att = ['SPEEDLIMIT', 'Struct_Cnd', 'Surface_Tp', 'F_F_Class']\n",
    "for d in dummy_att:\n",
    "    t = pd.get_dummies(data_model[d])\n",
    "    t.columns = [d+str(c) for c in t.columns]\n",
    "    data_model = pd.concat([data_model, t], axis=1)\n",
    "# aadt - log-transform\n",
    "data_model['log_aadt'] = np.log(data_model.AADT+1)\n",
    "# add segment type\n",
    "data_model['intersection'] = data_model.segment_id.map(lambda x: x[:2]!='00').astype(int)\n",
    "# features\n",
    "features = data_model.filter(regex='[0-9]').columns.tolist() + ['log_aadt', 'intersection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "#features = [u'pre_week', u'pre_month', u'pre_quarter', 'avg_week', u'AADT', u'SPEEDLIMIT',\n",
    "#            u'Struct_Cnd', u'Surface_Tp', u'F_F_Class', u'pre_week_adj', \n",
    "#            u'pre_month_adj', u'pre_quarter_adj']\n",
    "features += [u'pre_week', u'pre_month', u'pre_quarter', 'avg_week', 'concern_observed']\n",
    "lm_features = list(set(features) - set(['SPEEDLIMIT1', 'Struct_Cnd0', 'F_F_Class0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning\n",
    "This uses the model helpers above.  They're based on sklearn and implement a randomized grid search with K-fold crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train obs: 2396\n",
      "Test obs: 982\n"
     ]
    }
   ],
   "source": [
    "#Initialize data\n",
    "df = Indata(data_model, 'target')\n",
    "#Create train/test split\n",
    "df.tr_te_split(.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for model\n",
    "# class weight\n",
    "a = data_model['target'].value_counts(normalize=True)\n",
    "w = 1/a[1]\n",
    "#Model parameters\n",
    "params = dict()\n",
    "\n",
    "#cv parameters\n",
    "cvp = dict()\n",
    "cvp['pmetric'] = 'roc_auc'\n",
    "cvp['iter'] = 5 #number of iterations\n",
    "cvp['folds'] = 5 #folds for cv (default)\n",
    "cvp['shuffle'] = True\n",
    "\n",
    "#LR parameters\n",
    "mp = dict()\n",
    "mp['LogisticRegression'] = dict()\n",
    "mp['LogisticRegression']['penalty'] = ['l1','l2']\n",
    "mp['LogisticRegression']['C'] = ss.beta(a=5,b=2) #beta distribution for selecting reg strength\n",
    "mp['LogisticRegression']['class_weight'] = ['balanced']\n",
    "\n",
    "#RF model parameters\n",
    "mp['RandomForestClassifier'] = dict()\n",
    "mp['RandomForestClassifier']['n_estimators'] = [2**8] #number of trees in the forest\n",
    "mp['RandomForestClassifier']['max_features'] = ss.beta(a=5,b=1) #number of features at split\n",
    "mp['RandomForestClassifier']['max_leaf_nodes'] = ss.nbinom(n=2,p=0.001,loc=100) #max number of leaves to create\n",
    "#mp['RandomForestClassifier']['class_weight'] = ['balanced']\n",
    "mp['RandomForestClassifier']['class_weight'] = [{0:1,1:w}]\n",
    "\n",
    "\n",
    "#xgBoost model parameters\n",
    "mp['XGBClassifier'] = dict()\n",
    "mp['XGBClassifier']['max_depth'] = range(3, 7)\n",
    "mp['XGBClassifier']['min_child_weight'] = range(1, 5)\n",
    "mp['XGBClassifier']['learning_rate'] = ss.beta(a=2,b=15)\n",
    "mp['XGBClassifier']['scale_pos_weight'] = [w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize tuner\n",
    "tune = Tuner(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    6.9s finished\n"
     ]
    }
   ],
   "source": [
    "#Base XG model\n",
    "tune.tune('XG_base', 'XGBClassifier', feats, cvp, mp['XGBClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "#Base RF model\n",
    "tune.tune('RF_base', 'RandomForestClassifier', features, cvp, mp['RandomForestClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "#Base LR model\n",
    "tune.tune('LR_base', 'LogisticRegression', lm_features, cvp, mp['LogisticRegression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>params</th>\n",
       "      <th>name</th>\n",
       "      <th>m_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.539715</td>\n",
       "      <td>0.952102</td>\n",
       "      <td>{u'scale_pos_weight': 61.4181818182, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525479</td>\n",
       "      <td>0.956909</td>\n",
       "      <td>{u'scale_pos_weight': 61.4181818182, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.524591</td>\n",
       "      <td>0.967394</td>\n",
       "      <td>{u'scale_pos_weight': 61.4181818182, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.608078</td>\n",
       "      <td>0.882563</td>\n",
       "      <td>{u'scale_pos_weight': 61.4181818182, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.526709</td>\n",
       "      <td>0.974394</td>\n",
       "      <td>{u'scale_pos_weight': 61.4181818182, u'learnin...</td>\n",
       "      <td>XG_base</td>\n",
       "      <td>XGBClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.717272</td>\n",
       "      <td>0.998635</td>\n",
       "      <td>{u'max_features': 0.706051623971, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663105</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>{u'max_features': 0.941033684712, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.689439</td>\n",
       "      <td>0.998813</td>\n",
       "      <td>{u'max_features': 0.967993207111, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.674742</td>\n",
       "      <td>0.998373</td>\n",
       "      <td>{u'max_features': 0.976994307592, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.656144</td>\n",
       "      <td>0.998308</td>\n",
       "      <td>{u'max_features': 0.962203448832, u'max_leaf_n...</td>\n",
       "      <td>RF_base</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.608300</td>\n",
       "      <td>0.795809</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.871527741526, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608194</td>\n",
       "      <td>0.795881</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.876545689479, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602719</td>\n",
       "      <td>0.798138</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.813709390714, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.608303</td>\n",
       "      <td>0.796070</td>\n",
       "      <td>{u'penalty': u'l2', u'C': 0.899294845826, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.603745</td>\n",
       "      <td>0.798125</td>\n",
       "      <td>{u'penalty': u'l1', u'C': 0.782749330292, u'cl...</td>\n",
       "      <td>LR_base</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  mean_train_score  \\\n",
       "0         0.539715          0.952102   \n",
       "1         0.525479          0.956909   \n",
       "2         0.524591          0.967394   \n",
       "3         0.608078          0.882563   \n",
       "4         0.526709          0.974394   \n",
       "0         0.717272          0.998635   \n",
       "1         0.663105          0.998573   \n",
       "2         0.689439          0.998813   \n",
       "3         0.674742          0.998373   \n",
       "4         0.656144          0.998308   \n",
       "0         0.608300          0.795809   \n",
       "1         0.608194          0.795881   \n",
       "2         0.602719          0.798138   \n",
       "3         0.608303          0.796070   \n",
       "4         0.603745          0.798125   \n",
       "\n",
       "                                              params     name  \\\n",
       "0  {u'scale_pos_weight': 61.4181818182, u'learnin...  XG_base   \n",
       "1  {u'scale_pos_weight': 61.4181818182, u'learnin...  XG_base   \n",
       "2  {u'scale_pos_weight': 61.4181818182, u'learnin...  XG_base   \n",
       "3  {u'scale_pos_weight': 61.4181818182, u'learnin...  XG_base   \n",
       "4  {u'scale_pos_weight': 61.4181818182, u'learnin...  XG_base   \n",
       "0  {u'max_features': 0.706051623971, u'max_leaf_n...  RF_base   \n",
       "1  {u'max_features': 0.941033684712, u'max_leaf_n...  RF_base   \n",
       "2  {u'max_features': 0.967993207111, u'max_leaf_n...  RF_base   \n",
       "3  {u'max_features': 0.976994307592, u'max_leaf_n...  RF_base   \n",
       "4  {u'max_features': 0.962203448832, u'max_leaf_n...  RF_base   \n",
       "0  {u'penalty': u'l2', u'C': 0.871527741526, u'cl...  LR_base   \n",
       "1  {u'penalty': u'l2', u'C': 0.876545689479, u'cl...  LR_base   \n",
       "2  {u'penalty': u'l1', u'C': 0.813709390714, u'cl...  LR_base   \n",
       "3  {u'penalty': u'l2', u'C': 0.899294845826, u'cl...  LR_base   \n",
       "4  {u'penalty': u'l1', u'C': 0.782749330292, u'cl...  LR_base   \n",
       "\n",
       "                   m_name  \n",
       "0           XGBClassifier  \n",
       "1           XGBClassifier  \n",
       "2           XGBClassifier  \n",
       "3           XGBClassifier  \n",
       "4           XGBClassifier  \n",
       "0  RandomForestClassifier  \n",
       "1  RandomForestClassifier  \n",
       "2  RandomForestClassifier  \n",
       "3  RandomForestClassifier  \n",
       "4  RandomForestClassifier  \n",
       "0      LogisticRegression  \n",
       "1      LogisticRegression  \n",
       "2      LogisticRegression  \n",
       "3      LogisticRegression  \n",
       "4      LogisticRegression  "
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display results\n",
    "tune.grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RF_base model with 47 features\n",
      "f1_score:  0.0\n",
      "roc auc:  0.733706438041\n",
      "brier_score:  0.0202538773754\n",
      "Fitting LR_base model with 39 features\n",
      "f1_score:  0.048275862069\n",
      "roc auc:  0.68536159403\n",
      "brier_score:  0.203287799165\n",
      "Fitting XG_base model with 34 features\n",
      "f1_score:  0.0366972477064\n",
      "roc auc:  0.493490513614\n",
      "brier_score:  0.197440885928\n"
     ]
    }
   ],
   "source": [
    "# Run test\n",
    "test = Tester(df)\n",
    "test.init_tuned(tune)\n",
    "test.run_tuned('RF_base', cal=False)\n",
    "test.run_tuned('LR_base', cal=False)\n",
    "test.run_tuned('XG_base', cal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('avg_week', 0.32507639564755558), ('log_aadt', 0.22485744120301215), (u'pre_quarter_adj', 0.059371346519650092), (u'pre_quarter', 0.053484976004599435), ('SPEEDLIMIT65', 0.029754818922582284), ('SPEEDLIMIT30', 0.026276479394543847), (u'pre_month', 0.024586739996401846), ('intersection', 0.024488403968206816), ('Struct_Cnd3', 0.024207253081065982), ('SPEEDLIMIT25', 0.022829649253267047), ('F_F_Class7', 0.022777549405308163), ('Struct_Cnd2', 0.021728773144841725), ('SPEEDLIMIT20', 0.018320723235497657), (u'pre_month_adj', 0.017671485215904507), ('Struct_Cnd1', 0.015729358042721284), ('SPEEDLIMIT35', 0.011669354535281845), ('Struct_Cnd4', 0.010434214036467788), ('F_F_Class4', 0.0075860682292713082), ('F_F_Class3', 0.0074437118448320216), ('Surface_Tp6', 0.0073283207325600935), ('SPEEDLIMIT1', 0.0062811429632111844), ('SPEEDLIMIT15', 0.006004979081340696), (u'pre_week_adj', 0.0054213710980202815), ('F_F_Class1', 0.0049075051004588569), ('F_F_Class0', 0.0043596561595910435), ('Surface_Tp5', 0.0028551568001204931), ('Surface_Tp0', 0.0027466128922815692), ('Struct_Cnd0', 0.0024778497090247546), (u'pre_week', 0.0022512828703601735), ('F_F_Class5', 0.0020939453057341557), ('SPEEDLIMIT55', 0.0020059484456970813), ('Surface_Tp7', 0.0010305281421214619), ('F_F_Class2', 0.00086824280688757702), ('Surface_Tp2', 0.00035736776115004564), ('Surface_Tp3', 0.00035691258827885052), ('SPEEDLIMIT45', 0.00022138243300342793), ('Surface_Tp4', 9.0444766807650949e-05), ('Surface_Tp8', 3.7733640182676774e-05), ('SPEEDLIMIT10', 8.8750221565278202e-06), ('SPEEDLIMIT5', 0.0), ('Surface_Tp1', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Check feature importance\n",
    "f_importance = tune.best_models['RF_base']['m_fit'].feature_importances_\n",
    "fi = list(zip(features, f_importance))\n",
    "print sorted(fi, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57538461538461538"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying some other models\n",
    "minus_adj = list(set(lm_features) - set([x for x in lm_features if x.find('adj')!=-1]))\n",
    "lr = skl.LogisticRegression(**test.rundict['LR_base']['bp'])\n",
    "lr.fit(test.data.train_x[minus_adj], test.data.train_y)\n",
    "preds = lr.predict_proba(\n",
    "    test.data.test_x[minus_adj])[::,1]\n",
    "roc_auc_score(test.data.test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'pre_quarter_adj', u'pre_week_adj', u'pre_month_adj']"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying some other models\n",
    "minus_adj = list(set(lm_features) - set([x for x in lm_features if x.find('adj')!=-1]))\n",
    "lr = skl.LogisticRegression(**test.rundict['LR_base']['bp'])\n",
    "lr.fit(test.data.train_x[minus_adj], test.data.train_y)\n",
    "preds = lr.predict_proba(\n",
    "    test.data.test_x[minus_adj])[::,1]\n",
    "roc_auc_score(test.data.test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/ipykernel_launcher.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55830546265328862"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = skl.LogisticRegression(**test.rundict['LR_base']['bp'])\n",
    "lr.fit(test.data.train_x['avg_week'].reshape(-1,1), test.data.train_y)\n",
    "preds = lr.predict_proba(\n",
    "    test.data.test_x['avg_week'].reshape(-1,1))[::,1]\n",
    "roc_auc_score(test.data.test_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift chart by \"risk bin\"\n",
    "The classifier problem is difficult because the classes are unbalanced (.05% have crashes at target week).  More useful are the probabilities being produced by the model, which give some idea of risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lift_chart(x_col, y_col, data, ax=None):\n",
    "\n",
    "    p = sns.barplot(x=x_col, y=y_col, data=data, \n",
    "                    palette='Reds', ax = None, ci=None)\n",
    "    vals = p.get_yticks()\n",
    "    p.set_yticklabels(['{:3.0f}%'.format(i*100) for i in vals])\n",
    "    xvals = [x.get_text().split(',')[-1].strip(']') for x in p.get_xticklabels()]\n",
    "    xvals = ['{:3.0f}%'.format(float(x)*100) for x in xvals]\n",
    "    p.set_xticklabels(xvals)\n",
    "    p.set_facecolor('white')\n",
    "    p.set_xlabel('')\n",
    "    p.set_ylabel('')\n",
    "    p.set_title('Predicted probability vs actual percent')\n",
    "    return(p)\n",
    "    \n",
    "def density(data, score, ax=None):\n",
    "    p = sns.kdeplot(risk_df['risk_score'], ax=ax)\n",
    "    p.set_facecolor('white')\n",
    "    p.legend('')\n",
    "    p.set_xlabel('Predicted probability of crash')\n",
    "    p.set_title('KDE plot predictions')\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    982.000000\n",
      "mean       0.031068\n",
      "std        0.085986\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.011673\n",
      "max        0.660301\n",
      "Name: risk_score, dtype: float64\n",
      "categories\n",
      "(-1, 0]         628\n",
      "(0, 0.01]       105\n",
      "(0.01, 0.02]     53\n",
      "(0.02, 0.05]     63\n",
      "(0.05, 0.66]    133\n",
      "Name: crash, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "risk_scores = test.rundict['RF_base']['m_fit'].predict_proba(test.data.test_x[features])[:,1]\n",
    "risk_df = pd.DataFrame({'risk_score':risk_scores, 'crash':test.data.test_y})\n",
    "print risk_df.risk_score.describe()\n",
    "risk_df['categories'] = pd.cut(risk_df['risk_score'], bins=[-1, 0, .01, .02, .05, max(risk_scores)])\n",
    "risk_mean = risk_df.groupby('categories')['crash'].count()\n",
    "print risk_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b05b2d0>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFlCAYAAACqUeJLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117c90e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "lift_chart('categories', 'crash', risk_df, \n",
    "           ax=axes[1])\n",
    "density(risk_df, 'risk_score', ax=axes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output predictions\n",
    "# predict on all segments\n",
    "data_model['risk_score'] = test.rundict['RF_base']['m_fit'].predict_proba(data_model[features])[:,1]\n",
    "data_model.to_csv('seg_with_risk_score_adj.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sensitivity to week\n",
    "I predicted an arbitrary week as target here, but I'd like to see whether things change significantly if I change that week.  A good metric to measure that is brier score loss.  It'll be low throughout as the classifier doesn't perform great, but it shouldn't vary a huge amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model_for_week(weeks=[20, 30, 40, 50], output=False):\n",
    "    for w in [20, 30, 40, 50]:\n",
    "        print \"week \", w\n",
    "        crash_lags = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', w, 2016)\n",
    "        data = crash_lags.merge(data_segs, left_on='segment_id', right_on='segment_id')\n",
    "        adj_lags = get_adj_crash_lags(w, 2016)\n",
    "        data = data.merge(adj_lags, left_on='segment_id', right_index=True, suffixes=('', '_adj'))\n",
    "        data.fillna(0, inplace=True)\n",
    "        df = Indata(data, 'target')\n",
    "        # create train/test split\n",
    "        df.tr_te_split(.7)\n",
    "        test = Tester(df)\n",
    "        test.init_tuned(tune)\n",
    "        test.run_tuned('LR_base', cal=False)\n",
    "        print '\\n'\n",
    "    if output==True:\n",
    "        return(test.rundict['LR_base']['m_fit'].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week  20\n",
      "Train obs: 2367\n",
      "Test obs: 1011\n",
      "Fitting LR_base model with 12 features\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"[u'pre_week_scaled' u'pre_month_scaled' u'pre_quarter_scaled'\\n 'avg_week_scaled' u'AADT_scaled' u'SPEEDLIMIT_scaled' u'Struct_Cnd_scaled'\\n u'Surface_Tp_scaled' u'F_F_Class_scaled' u'pre_week_adj_scaled'\\n u'pre_month_adj_scaled' u'pre_quarter_adj_scaled'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-78ff6e31933f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_model_for_week\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-9c5526570564>\u001b[0m in \u001b[0;36mrun_model_for_week\u001b[0;34m(weeks, output)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LR_base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e9484aaf2483>\u001b[0m in \u001b[0;36mrun_tuned\u001b[0;34m(self, name, cal, cal_m)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m#Run from tuned set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_tuned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_m\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrundict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrundict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m#Output rundict to csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e9484aaf2483>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self, name, model, features, cal, cal_m)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mcal_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mrnd_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[u'pre_week_scaled' u'pre_month_scaled' u'pre_quarter_scaled'\\n 'avg_week_scaled' u'AADT_scaled' u'SPEEDLIMIT_scaled' u'Struct_Cnd_scaled'\\n u'Surface_Tp_scaled' u'F_F_Class_scaled' u'pre_week_adj_scaled'\\n u'pre_month_adj_scaled' u'pre_quarter_adj_scaled'] not in index\""
     ]
    }
   ],
   "source": [
    "run_model_for_week()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# week predictions output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
