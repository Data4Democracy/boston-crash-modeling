{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAR Model for crash prediction\n",
    "### Developed by: bpben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from glob import glob\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "from theano import shared\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import theano.sparse\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "The approach here is to create 3 time-lag features:\n",
    "\n",
    "1. crashes in the past week\n",
    "2. crashes in the past month\n",
    "3. crashes in the past quarter (three months)\n",
    "4. average crashes per week up to target week\n",
    "\n",
    "All features except 4 are calculated to exclude one another.  That is, crashes in the past month does not include the past week's crashes.  Crashes in the past quarter do not include the past month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEG_CHARS = ['AADT', 'SPEEDLIMIT', 'Struct_Cnd', 'Surface_Tp', 'F_F_Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('../data/processed/vz_predict_dataset.csv.gz', \n",
    "                   compression='gzip', dtype={'segment_id':'str'})\n",
    "data.sort_values(['segment_id', 'year','week'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get segments with non-zero crashes\n",
    "data_nonzero = data.set_index('segment_id').loc[data.groupby('segment_id').crash.sum()>0]\n",
    "data_nonzero.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_crash_data(data, col, target_week, target_year):\n",
    "    \"\"\" formats crash data for train/test \n",
    "    target_week: week to predict (make into binary target)\n",
    "    target_year: year for predicted week\n",
    "    note: data must be available for 4 months prior to target\n",
    "    gets previous week count, previous month count, previous quarter count, avg per week\n",
    "    \"\"\"\n",
    "    assert target_week>16\n",
    "    pre_week = target_week - 1\n",
    "    pre_month = range(pre_week-4, target_week)\n",
    "    pre_quarter = range(pre_month[0]-12, target_week)\n",
    "    \n",
    "    # week interval for each segment\n",
    "    # full range = pre_quarter : target\n",
    "    sliced = data.loc[(slice(None),slice(target_year,target_year), slice(1, target_week)),:]\n",
    "    week_data = sliced[col].unstack(2)\n",
    "    week_data.reset_index(level=1, inplace=True)\n",
    "    \n",
    "    # aggregate\n",
    "    week_data['pre_month'] = week_data[pre_month].sum(axis=1)\n",
    "    week_data['pre_quarter'] = week_data[pre_quarter].sum(axis=1)\n",
    "    week_data['pre_week'] = week_data[pre_week]\n",
    "\n",
    "    # avg as of target week\n",
    "    except_target = data.loc[(slice(None),\n",
    "                       slice(target_year,target_year),\n",
    "                       slice(target_week,None)),:].index\n",
    "    avg_week = data.drop(except_target)\n",
    "    avg_week = avg_week.reset_index().groupby('segment_id')[col].mean()\n",
    "    avg_week.name = 'avg_week'\n",
    "    # join to week data\n",
    "    week_data = week_data.join(avg_week)\n",
    "\n",
    "    # binarize target\n",
    "    week_data['target'] = (week_data[target_week]>0).astype(int)\n",
    "    week_data = week_data.reset_index()\n",
    "\n",
    "    return(week_data[['segment_id','target', 'pre_week',\n",
    "                      'pre_month', 'pre_quarter', 'avg_week']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_lags = format_crash_data(data_nonzero.set_index(['segment_id','year','week']), 'crash', 19, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_segs = data_nonzero.groupby('segment_id')[SEG_CHARS].max()\n",
    "data_segs = data.groupby('segment_id')[SEG_CHARS].max()\n",
    "data_segs.reset_index(inplace=True)\n",
    "# add crash lags to segments\n",
    "data_model = crash_lags.merge(data_segs, on='segment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in adj\n",
    "adj = pd.read_csv('../data/processed/adjacency_info.csv', dtype={'segment_id':'str'})\n",
    "# only include adj that are in data model\n",
    "adj = adj[adj.segment_id.isin(data_model.segment_id)]\n",
    "# create adj matrix (1 if is adjacent, 0 otherwise)\n",
    "adj_mat = adj.merge(adj, on='orig_id')\n",
    "adj_mat = adj_mat.drop(['orig_id'], axis=1)\n",
    "adj_mat = pd.concat([adj_mat.segment_id_x, pd.get_dummies(adj_mat.segment_id_y)], axis=1)\n",
    "adj_mat = adj_mat.groupby('segment_id_x').max()\n",
    "adj_mat = adj_mat.apply(lambda x: x.astype(float))\n",
    "# fill diagonal (self) with zero\n",
    "np.fill_diagonal(adj_mat.values, 10**-6)\n",
    "adj_mat.index.name = 'segment_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add adjacency to maintain order\n",
    "data_model = data_model.merge(adj_mat, left_on='segment_id', \n",
    "                              right_index=True, how='left')\n",
    "amat = data_model[data_model.segment_id.unique()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_model['speed_g30'] = (data_model.SPEEDLIMIT>30).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "N = len(data_model) # number of observations\n",
    "O = data_model.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try observed as 52 trials\n",
    "#o_trials = data_nonzero.set_index(['segment_id','week'])['crash'].unstack()\n",
    "#o_trials = o_trials.loc[data_model.segment_id].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working CAR class and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/theano/tensor/basic.py:2146: UserWarning: theano.tensor.round() changed its default from `half_away_from_zero` to `half_to_even` to have the same default as NumPy. Use the Theano flag `warn.round=False` to disable this warning.\n",
      "  \"theano.tensor.round() changed its default from\"\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named mkl\n",
      "Average ELBO = 6,047.1: 100%|██████████| 200000/200000 [11:08<00:00, 299.23it/s]   \n",
      "Finished [100%]: Average ELBO = 5,926.9\n",
      "  3%|▎         | 54/2000 [08:49<6:32:27, 12.10s/it] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fb56e1b20ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mobs_crash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'obs_crash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnjobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pymc3/sampling.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain, njobs, tune, progressbar, model, random_seed)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0msample_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msample_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/pymc3/sampling.pyc\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                                                      \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrseed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                                                      \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                                                      **kwargs) for i in range(njobs))\n\u001b[0m\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/site-packages/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/B/anaconda/envs/boston-crash-model/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CAR(pm.distributions.distribution.Continuous):\n",
    "    def __init__(self, alpha, adjacency, *args, **kwargs):\n",
    "        if not isinstance(adjacency, np.ndarray):\n",
    "            raise ValueError(\"Adjacency matrix is not an ndarray.\")\n",
    "        n, m = adjacency.shape\n",
    "        if n != m or np.any(adjacency != adjacency.T):\n",
    "            raise ValueError('Adjacency matrix must be symmetric.')\n",
    "        if 'shape' in kwargs and kwargs['shape'] == n:\n",
    "            raise ValueError('Invalid shape: Must match matrix dimension.')\n",
    "        kwargs['shape'] = n\n",
    "        super(CAR, self).__init__(*args, **kwargs)\n",
    "        self.n = n\n",
    "        self.alpha = tt.as_tensor_variable(alpha)\n",
    "        adjacency_sparse = scipy.sparse.csr_matrix(adjacency)\n",
    "        self.adjacency = theano.sparse.as_sparse_variable(adjacency_sparse)\n",
    "        self.neighbors = tt.as_tensor_variable(adjacency.sum(0))\n",
    "        self.mean = tt.zeros(n)\n",
    "        self.median = self.mean\n",
    "        adj = adjacency.astype('d').copy()\n",
    "        sqrt_neighbors = 1 / np.sqrt(adjacency.sum(0))\n",
    "        adj[:] *= sqrt_neighbors[:, None]\n",
    "        adj[:] *= sqrt_neighbors[None, :]\n",
    "        self.eigs = scipy.linalg.eigvalsh(adj)\n",
    "\n",
    "    def logp(self, x):\n",
    "        Wx = theano.sparse.dot(self.adjacency, x.reshape((self.n, 1)))\n",
    "        tau_dot_x = self.neighbors * x - self.alpha * Wx.ravel()\n",
    "        logdet = tt.log(1 - self.alpha * self.eigs).sum()\n",
    "        logp = 0.5 * (logdet - tt.dot(x, tau_dot_x))\n",
    "        return logp\n",
    "\n",
    "with pm.Model() as model:\n",
    "    b0 = pm.Normal('intercept', mu=5.4, sd=2)\n",
    "    b1 = pm.Cauchy('avg_week', alpha=0, beta=2)\n",
    "    b2 = pm.Uniform('speed_limit_g30', lower=0, upper=1)\n",
    "\n",
    "    # random effect precision parameter\n",
    "    sd = pm.HalfCauchy('sd', beta=2)\n",
    "    # strength of spatial correlation\n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    phi = CAR('mu_phi', alpha=alpha, adjacency=amat)\n",
    "    \n",
    "    theta = pm.invlogit(b0 + b1 * data_model.avg_week.values + \\\n",
    "                        b2 * data_model.speed_g30.values + sd * phi)\n",
    "    \n",
    "    obs_crash = pm.Binomial('obs_crash', n=N, p=theta, observed=O)\n",
    "    \n",
    "    trace = pm.sample(2000, tune=1000, njobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pm.traceplot(trace[1500:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppc = pm.sample_ppc(trace[1000:], model=model, samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y = np.mean(ppc['obs_crash'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert target to binary\n",
    "O_int = (O>0).astype(int)\n",
    "roc_auc_score(O_int, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert target to binary\n",
    "O_int = (O>0).astype(int)\n",
    "roc_auc_score(O_int, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MAE\n",
    "print \"MAE is : {}\".format(\n",
    "    np.mean(abs(pred_y - O_int))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = road_make(inters_fp, non_inters_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run 53 times, for each week\n",
    "preds_all = data_model['segment_id'].values.reshape(-1,1)\n",
    "for i in range(54):\n",
    "    print 'run ' + str(i)\n",
    "    ppc = pm.sample_ppc(trace[1500:], model=model, samples=5000)\n",
    "    pred_y = np.mean(ppc['obs_crash'], axis=0).reshape(-1,1)\n",
    "    preds_all = np.concatenate([preds_all, pred_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# week predictions\n",
    "preds_all_df = pd.DataFrame(preds_all)\n",
    "preds_all_df.columns = ['segment_id'] + range(54)\n",
    "preds_all_df.to_csv('../data/processed/car_preds_weekly.csv')\n",
    "#pd.DataFrame(zip(data_model['segment_id'].values, pred_y),\n",
    "#            columns=['segment_id', 'pred']).to_csv('../data/processed/car_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output predicted probabilities\n",
    "pd.DataFrame(zip(data_model['segment_id'].values, pred_y),\n",
    "            columns=['segment_id', 'pred']).to_csv('../data/processed/car_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
