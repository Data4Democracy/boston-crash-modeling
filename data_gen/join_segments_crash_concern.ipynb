{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Joining segments (intersection and non-intersection) to crash/concern data\n",
    "# Draws on: http://bit.ly/2m7469y\n",
    "# Developed by: bpben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fiona\n",
    "import json\n",
    "import os\n",
    "import pyproj\n",
    "import rtree\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, MultiPoint, shape, mapping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Project projection = EPSG:3857\n",
    "PROJ = pyproj.Proj(init='epsg:3857')\n",
    "\n",
    "MAP_FP = './data/maps'\n",
    "DATA_FP = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_record(record, x, y, orig=None, new=PROJ):\n",
    "    \"\"\"\n",
    "    Reads record, outputs dictionary with point and properties\n",
    "    Specify orig if reprojecting\n",
    "    \"\"\"\n",
    "    if (orig is not None):\n",
    "        x, y = pyproj.transform(orig, new, x, y)\n",
    "    r_dict = {\n",
    "        'point': Point(float(x), float(y)),\n",
    "        'properties': r\n",
    "    }            \n",
    "    return(r_dict)\n",
    "\n",
    "def read_shp(fp):\n",
    "    \"\"\" Read shp, output tuple geometry + property \"\"\"\n",
    "    out = [(shape(line['geometry']),line['properties']) for line in fiona.open(fp)]\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read shp, output tuple geometry + property\n",
    "def read_shp(fp):\n",
    "    out = [(shape(line['geometry']),line['properties']) for line in fiona.open(fp)]\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make schema\n",
    "def make_schema(geometry, properties):\n",
    "    \"\"\"\n",
    "    Utility for making schema with 'str' value for each key in properties\n",
    "    \"\"\"\n",
    "    properties_dict = {k:'str' for k,v in properties.items()}\n",
    "    schema = {\n",
    "    'geometry': geometry,\n",
    "    'properties': properties_dict\n",
    "    }\n",
    "    return(schema)\n",
    "\n",
    "#Output as shapefile\n",
    "def write_shp(schema, fp, data, shape_key, prop_key):\n",
    "    # Write a new Shapefile\n",
    "    with fiona.open(fp, 'w', 'ESRI Shapefile', schema) as c:\n",
    "        for i in data:\n",
    "            c.write({\n",
    "                'geometry': mapping(i[shape_key]),\n",
    "                'properties': i[prop_key],\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in CAD crash data\n",
    "crash = []\n",
    "with open(DATA_FP + '/cad_crash_events_with_transport_2016_wgs84.csv') as f:\n",
    "    csv_reader = csv.DictReader(f)\n",
    "    for r in csv_reader:\n",
    "        #Some crash 0 / blank coordinates\n",
    "        if r['X']!='':\n",
    "            crash.append(\n",
    "                read_record(r, r['X'], r['Y'],\n",
    "                           orig = pyproj.Proj(init='epsg:4326'))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in vision zero data\n",
    "concern = []\n",
    "#Have to use pandas read_csv, unicode trubs\n",
    "concern_raw = pd.read_csv(DATA_FP + '/Vision_Zero_Entry.csv')    \n",
    "concern_raw = concern_raw.to_dict('records')\n",
    "for r in concern_raw:\n",
    "    concern.append(\n",
    "        read_record(r, r['X'], r['Y'], \n",
    "                    orig = pyproj.Proj(init='epsg:4326'))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in segments\n",
    "inter = read_shp(MAP_FP + '/inters_segments.shp')\n",
    "non_inter = read_shp(MAP_FP + '/non_inters_segments.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combine inter + non_inter\n",
    "combined_seg = inter + non_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create spatial index for quick lookup\n",
    "segments_index = rtree.index.Index()\n",
    "for idx, element in enumerate(combined_seg):\n",
    "    segments_index.insert(idx, element[0].bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_nearest(records, segments, segments_index, tolerance):\n",
    "    \"\"\" Finds nearest segment to records\n",
    "    tolerance : max units distance from record point to consider\n",
    "    \"\"\"\n",
    "    \n",
    "    for record in records:\n",
    "        record_point = record['point']\n",
    "        record_buffer_bounds = record_point.buffer(tolerance).bounds\n",
    "        nearby_segments = segments_index.intersection(record_buffer_bounds)\n",
    "        segment_id_with_distance = [\n",
    "            #Get db index and distance to point\n",
    "            (\n",
    "                segments[segment_id][1]['id'],\n",
    "                segments[segment_id][0].distance(record_point)\n",
    "            )\n",
    "            for segment_id in nearby_segments\n",
    "            ]\n",
    "        #Find nearest segment\n",
    "        if len(segment_id_with_distance):\n",
    "            nearest = min(segment_id_with_distance, key=lambda tup: tup[1])\n",
    "            db_segment_id = nearest[0]\n",
    "            #Add db_segment_id to record\n",
    "            record['properties']['near_id'] = db_segment_id\n",
    "        #If no segment matched, populate key = ''\n",
    "        else:\n",
    "            record['properties']['near_id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find nearest crashes - 30 tolerance\n",
    "find_nearest(crash, combined_seg, segments_index, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find nearest concerns - 20 tolerance\n",
    "find_nearest(concern, combined_seg, segments_index, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write concerns\n",
    "concern_schema = make_schema('Point', concern[0]['properties'])\n",
    "write_shp(concern_schema, MAP_FP + '/concern_joined.shp', concern, 'point', 'properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write crash\n",
    "crash_schema = make_schema('Point', crash[0]['properties'])\n",
    "write_shp(crash_schema, MAP_FP + '/crash_joined.shp', crash, 'point', 'properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write properties to json\n",
    "with open(DATA_FP + '/crash_joined.json', 'w') as f:\n",
    "    json.dump([c['properties'] for c in crash], f)\n",
    "with open(DATA_FP + '/concern_joined.json', 'w') as f:\n",
    "    json.dump([c['properties'] for c in concern], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
